# pyright: reportMissingImports=false
# type: ignore
"""
VTOX åˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤å¯åŠ¨å™¨

åŠŸèƒ½ç‰¹ç‚¹:
1. ä¸€é”®å¯åŠ¨å®Œæ•´é›†ç¾¤ - è‡ªåŠ¨å¯åŠ¨æ‰€æœ‰å¾®æœåŠ¡ç»„ä»¶
2. çµæ´»éƒ¨ç½²æ¨¡å¼ - æ”¯æŒå¼€å‘/æµ‹è¯•/ç”Ÿäº§ç¯å¢ƒ
3. å¥åº·çŠ¶æ€ç›‘æ§ - å®æ—¶ç›‘æ§å„æœåŠ¡çŠ¶æ€
4. æ•…éšœè‡ªåŠ¨æ¢å¤ - æœåŠ¡å¼‚å¸¸æ—¶è‡ªåŠ¨é‡å¯
5. æ¸è¿›å¼æ‰©å±• - æ”¯æŒåŠ¨æ€æ·»åŠ WorkerèŠ‚ç‚¹

ä½¿ç”¨æ–¹å¼:
python cluster/start_cluster.py --mode=development
python cluster/start_cluster.py --mode=production --workers=6
"""

import asyncio
import argparse
import logging
import signal
import sys
import time
from typing import Dict, List, Optional
from pathlib import Path
import redis.asyncio as redis

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_path = Path(__file__).parent.parent / "backend"
if str(backend_path) not in sys.path:
    sys.path.insert(0, str(backend_path))

# æ·»åŠ å·¥ä½œç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

try:
    # ç®€åŒ–å¯¼å…¥é€»è¾‘ï¼Œä¼˜å…ˆä½¿ç”¨ app è·¯å¾„
    from app.services.cluster.service_registry import ServiceRegistry, get_service_registry
    from app.services.cluster.coordinator import DiagnosisCoordinator, get_diagnosis_coordinator
    from app.services.cluster.worker_node import DistributedWorkerNode, create_worker_config
except ImportError as e:
    # å¦‚æœå¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
    import os
    print(f"é›†ç¾¤æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"backendè·¯å¾„: {backend_path}")
    print(f"backendè·¯å¾„å­˜åœ¨: {backend_path.exists()}")
    print(f"project_root: {project_root}")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # æ£€æŸ¥å…·ä½“æ¨¡å—æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    service_registry_path = backend_path / "app" / "services" / "cluster" / "service_registry.py"
    coordinator_path = backend_path / "app" / "services" / "cluster" / "coordinator.py"
    worker_node_path = backend_path / "app" / "services" / "cluster" / "worker_node.py"
    
    print(f"service_registry.pyå­˜åœ¨: {service_registry_path.exists()}")
    print(f"coordinator.pyå­˜åœ¨: {coordinator_path.exists()}")
    print(f"worker_node.pyå­˜åœ¨: {worker_node_path.exists()}")
    
    # æ£€æŸ¥__init__.pyæ–‡ä»¶
    cluster_init_path = backend_path / "app" / "services" / "cluster" / "__init__.py"
    app_init_path = backend_path / "app" / "__init__.py"
    services_init_path = backend_path / "app" / "services" / "__init__.py"
    
    print(f"cluster/__init__.pyå­˜åœ¨: {cluster_init_path.exists()}")
    print(f"app/__init__.pyå­˜åœ¨: {app_init_path.exists()}")
    print(f"services/__init__.pyå­˜åœ¨: {services_init_path.exists()}")
    
    print(f"å½“å‰sys.pathå‰5é¡¹: {sys.path[:5]}")
    print("\nè¯·ç¡®ä¿ï¼š")
    print("1. æ‰€æœ‰å¿…è¦çš„__init__.pyæ–‡ä»¶éƒ½å­˜åœ¨")
    print("2. ä»vtoxæ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    print("3. backendç›®å½•ç»“æ„å®Œæ•´")
    
    # é€€å‡ºç¨‹åºä½†ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ç±»å‹æ£€æŸ¥
    print(f"\né€€å‡ºç¨‹åº: é›†ç¾¤æ¨¡å—å¯¼å…¥å¤±è´¥")
    import sys
    sys.exit(1)

logger = logging.getLogger("cluster-manager")

class ClusterManager:
    """åˆ†å¸ƒå¼é›†ç¾¤ç®¡ç†å™¨"""
    
    def __init__(self, mode: str = "development"):
        self.mode = mode
        self.redis_url = "redis://localhost:6379"
        self.redis_client = None
        
        # æœåŠ¡ç»„ä»¶
        self.service_registry: Optional[ServiceRegistry] = None
        self.coordinator: Optional[DiagnosisCoordinator] = None
        self.worker_nodes: List[DistributedWorkerNode] = []
        
        # é›†ç¾¤çŠ¶æ€
        self.is_running = False
        self.shutdown_event = asyncio.Event()
        
        # éƒ¨ç½²é…ç½®
        self.deployment_configs = {
            "development": {
                "workers": [
                    {"id": "worker_1", "host": "localhost", "port": 8002, "fault_types": ["turn_fault", "insulation"]},
                    {"id": "worker_2", "host": "localhost", "port": 8003, "fault_types": ["bearing", "eccentricity"]},
                    {"id": "worker_3", "host": "localhost", "port": 8004, "fault_types": ["broken_bar"]}
                ],
                "coordinator": {"host": "localhost", "port": 8001},
                "monitoring": {"enabled": True, "interval": 10}
            },
            "testing": {
                "workers": [
                    {"id": "test_worker_1", "host": "localhost", "port": 8005, "fault_types": ["turn_fault"]},
                    {"id": "test_worker_2", "host": "localhost", "port": 8006, "fault_types": ["bearing"]}
                ],
                "coordinator": {"host": "localhost", "port": 8001},
                "monitoring": {"enabled": True, "interval": 5}
            },
            "production": {
                "workers": [
                    {"id": "prod_worker_turn", "host": "0.0.0.0", "port": 8002, "fault_types": ["turn_fault"]},
                    {"id": "prod_worker_insul", "host": "0.0.0.0", "port": 8003, "fault_types": ["insulation"]},
                    {"id": "prod_worker_bear", "host": "0.0.0.0", "port": 8004, "fault_types": ["bearing"]},
                    {"id": "prod_worker_ecc", "host": "0.0.0.0", "port": 8005, "fault_types": ["eccentricity"]},
                    {"id": "prod_worker_bar", "host": "0.0.0.0", "port": 8006, "fault_types": ["broken_bar"]},
                    {"id": "prod_worker_agg", "host": "0.0.0.0", "port": 8007, "fault_types": ["turn_fault", "bearing"]}
                ],
                "coordinator": {"host": "0.0.0.0", "port": 8001},
                "monitoring": {"enabled": True, "interval": 15}
            }
        }
    
    async def initialize_cluster(self) -> bool:
        """åˆå§‹åŒ–é›†ç¾¤"""
        try:
            logger.info(f"ğŸ”§ åˆå§‹åŒ–VTOXåˆ†å¸ƒå¼é›†ç¾¤ - {self.mode}æ¨¡å¼")
            
            # è¿æ¥Redis
            self.redis_client = redis.from_url(
                self.redis_url,
                decode_responses=True,
                retry_on_timeout=True,
                health_check_interval=30
            )
            await self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
            
            # åˆå§‹åŒ–æœåŠ¡æ³¨å†Œè¡¨
            self.service_registry = await get_service_registry(self.redis_client)
            logger.info("âœ… æœåŠ¡æ³¨å†Œè¡¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–åè°ƒå™¨
            self.coordinator = await get_diagnosis_coordinator(self.redis_client)
            logger.info("âœ… è¯Šæ–­åè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é›†ç¾¤åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def start_cluster(self, custom_workers: Optional[int] = None) -> bool:
        """å¯åŠ¨åˆ†å¸ƒå¼é›†ç¾¤"""
        try:
            if self.is_running:
                logger.warning("âš ï¸ é›†ç¾¤å·²åœ¨è¿è¡Œä¸­")
                return True
            
            logger.info("ğŸš€ å¯åŠ¨VTOXåˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤")
            
            # è·å–éƒ¨ç½²é…ç½®
            config = self.deployment_configs.get(self.mode, self.deployment_configs["development"])
            
            # å¯åŠ¨åè°ƒå™¨
            await self._start_coordinator(config["coordinator"])
            
            # å¯åŠ¨WorkerèŠ‚ç‚¹
            worker_configs = config["workers"]
            if custom_workers:
                # è‡ªå®šä¹‰Workeræ•°é‡
                worker_configs = self._generate_worker_configs(custom_workers)
            
            await self._start_workers(worker_configs)
            
            # å¯åŠ¨ç›‘æ§
            if config["monitoring"]["enabled"]:
                await self._start_monitoring(config["monitoring"]["interval"])
            
            self.is_running = True
            
            logger.info("âœ… VTOXåˆ†å¸ƒå¼é›†ç¾¤å¯åŠ¨å®Œæˆ")
            logger.info(f"   ğŸ“Š åè°ƒå™¨: è¿è¡Œä¸­")
            logger.info(f"   ğŸ”§ WorkerèŠ‚ç‚¹: {len(self.worker_nodes)}ä¸ª")
            logger.info(f"   ğŸ’» éƒ¨ç½²æ¨¡å¼: {self.mode}")
            logger.info(f"   ğŸŒ Redisåœ°å€: {self.redis_url}")
            
            # æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
            await self._display_cluster_status()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨é›†ç¾¤å¤±è´¥: {e}")
            return False
    
    async def _start_coordinator(self, coordinator_config: Dict):
        """å¯åŠ¨åè°ƒå™¨"""
        try:
            logger.info("ğŸ“Š å¯åŠ¨è¯Šæ–­åè°ƒå™¨...")
            
            # æ£€æŸ¥åè°ƒå™¨æ˜¯å¦å·²åˆå§‹åŒ–
            if self.coordinator is None:
                raise Exception("åè°ƒå™¨æœªåˆå§‹åŒ–")
            
            # åè°ƒå™¨åœ¨å½“å‰è¿›ç¨‹ä¸­è¿è¡Œ
            success = await self.coordinator.start_coordination()
            if success:
                logger.info(f"âœ… åè°ƒå™¨å¯åŠ¨æˆåŠŸ: {coordinator_config['host']}:{coordinator_config['port']}")
            else:
                raise Exception("åè°ƒå™¨å¯åŠ¨å¤±è´¥")
                
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨åè°ƒå™¨å¤±è´¥: {e}")
            raise
    
    async def _start_workers(self, worker_configs: List[Dict]):
        """å¯åŠ¨WorkerèŠ‚ç‚¹"""
        try:
            logger.info(f"ğŸ”§ å¯åŠ¨{len(worker_configs)}ä¸ªWorkerèŠ‚ç‚¹...")
            
            for worker_config in worker_configs:
                try:
                    # åˆ›å»ºWorkeré…ç½®
                    config = create_worker_config(
                        worker_id=worker_config["id"],
                        host=worker_config["host"],
                        port=worker_config["port"],
                        fault_types=worker_config["fault_types"],
                        redis_url=self.redis_url
                    )
                    
                    # åˆ›å»ºå¹¶å¯åŠ¨Worker
                    worker = DistributedWorkerNode(config)
                    
                    if await worker.initialize():
                        if await worker.start_worker():
                            self.worker_nodes.append(worker)
                            logger.info(f"âœ… Workerå¯åŠ¨æˆåŠŸ: {worker_config['id']} "
                                      f"({','.join(worker_config['fault_types'])})")
                        else:
                            logger.error(f"âŒ Workerå¯åŠ¨å¤±è´¥: {worker_config['id']}")
                    else:
                        logger.error(f"âŒ Workeråˆå§‹åŒ–å¤±è´¥: {worker_config['id']}")
                        
                except Exception as e:
                    logger.error(f"âŒ å¯åŠ¨Workerå¼‚å¸¸: {worker_config['id']} - {e}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸå¯åŠ¨{len(self.worker_nodes)}ä¸ªWorkerèŠ‚ç‚¹")
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨WorkerèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    def _generate_worker_configs(self, num_workers: int) -> List[Dict]:
        """ç”ŸæˆWorkeré…ç½®"""
        fault_types_pool = ["turn_fault", "insulation", "bearing", "eccentricity", "broken_bar"]
        worker_configs = []
        
        for i in range(num_workers):
            # åˆ†é…æ•…éšœç±»å‹ (è½®è¯¢åˆ†é…)
            fault_type = fault_types_pool[i % len(fault_types_pool)]
            
            config = {
                "id": f"dynamic_worker_{i+1}",
                "host": "localhost" if self.mode == "development" else "0.0.0.0",
                "port": 8002 + i,
                "fault_types": [fault_type]
            }
            worker_configs.append(config)
        
        return worker_configs
    
    async def _start_monitoring(self, interval: int):
        """å¯åŠ¨é›†ç¾¤ç›‘æ§"""
        try:
            logger.info(f"ğŸ“ˆ å¯åŠ¨é›†ç¾¤ç›‘æ§ (é—´éš”: {interval}ç§’)")
            
            # åˆ›å»ºç›‘æ§ä»»åŠ¡
            asyncio.create_task(self._monitoring_loop(interval))
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")
    
    async def _monitoring_loop(self, interval: int):
        """ç›‘æ§å¾ªç¯"""
        while self.is_running:
            try:
                await self._collect_cluster_metrics()
                await asyncio.sleep(interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    async def _collect_cluster_metrics(self):
        """æ”¶é›†é›†ç¾¤æŒ‡æ ‡"""
        try:
            # æ£€æŸ¥ç»„ä»¶æ˜¯å¦å·²åˆå§‹åŒ–
            if self.service_registry is None or self.coordinator is None or self.redis_client is None:
                logger.warning("âš ï¸ é›†ç¾¤ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–ï¼Œè·³è¿‡æŒ‡æ ‡æ”¶é›†")
                return
            
            # è·å–æœåŠ¡ç»Ÿè®¡
            service_stats = await self.service_registry.get_service_stats()
            
            # è·å–åè°ƒå™¨ç»Ÿè®¡
            coordinator_stats = await self.coordinator.get_coordinator_stats()
            
            # è·å–Workerç»Ÿè®¡
            worker_stats = []
            for worker in self.worker_nodes:
                try:
                    stats = await worker.get_worker_stats()
                    worker_stats.append(stats)
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–Workerç»Ÿè®¡å¤±è´¥: {worker.config.worker_id}")
            
            # è®°å½•é›†ç¾¤æŒ‡æ ‡åˆ°Redis
            cluster_metrics = {
                "timestamp": time.time(),
                "service_stats": service_stats,
                "coordinator_stats": coordinator_stats,
                "worker_stats": worker_stats,
                "cluster_health": self._calculate_cluster_health(service_stats, worker_stats)
            }
            
            await self.redis_client.xadd(
                "vtox:cluster:metrics",
                {k: str(v) for k, v in cluster_metrics.items()},
                maxlen=500
            )
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†é›†ç¾¤æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _calculate_cluster_health(self, service_stats: Dict, worker_stats: List[Dict]) -> float:
        """è®¡ç®—é›†ç¾¤å¥åº·åº¦"""
        try:
            health_factors = []
            
            # æœåŠ¡å¥åº·åº¦
            total_services = service_stats.get("total_services", 0)
            healthy_services = service_stats.get("healthy_services", 0)
            if total_services > 0:
                service_health = healthy_services / total_services
                health_factors.append(service_health)
            
            # Workerå¥åº·åº¦
            healthy_workers = sum(1 for w in worker_stats 
                                if w.get("resource_metrics", {}).get("healthy", False))
            if worker_stats:
                worker_health = healthy_workers / len(worker_stats)
                health_factors.append(worker_health)
            
            # è®¡ç®—å¹³å‡å¥åº·åº¦
            if health_factors:
                return sum(health_factors) / len(health_factors)
            
            return 0.5  # é»˜è®¤å¥åº·åº¦
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—é›†ç¾¤å¥åº·åº¦å¤±è´¥: {e}")
            return 0.0
    
    async def _display_cluster_status(self):
        """æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€"""
        try:
            print("\n" + "="*80)
            print("ğŸ—ï¸  VTOX åˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤çŠ¶æ€")
            print("="*80)
            
            # æ£€æŸ¥ç»„ä»¶æ˜¯å¦å·²åˆå§‹åŒ–
            if self.service_registry is None or self.coordinator is None:
                print("âš ï¸ é›†ç¾¤ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–")
                return
            
            # æœåŠ¡æ³¨å†Œè¡¨çŠ¶æ€
            service_stats = await self.service_registry.get_service_stats()
            print(f"ğŸ“Š æœåŠ¡æ³¨å†Œè¡¨:")
            print(f"   æ€»æœåŠ¡æ•°: {service_stats.get('total_services', 0)}")
            print(f"   å¥åº·æœåŠ¡: {service_stats.get('healthy_services', 0)}")
            print(f"   ä¸å¥åº·æœåŠ¡: {service_stats.get('unhealthy_services', 0)}")
            
            # åè°ƒå™¨çŠ¶æ€
            coordinator_stats = await self.coordinator.get_coordinator_stats()
            print(f"ğŸ“‹ è¯Šæ–­åè°ƒå™¨:")
            print(f"   çŠ¶æ€: {coordinator_stats.get('coordinator_status', 'unknown')}")
            print(f"   å·²åˆ†é…ä»»åŠ¡: {coordinator_stats.get('tasks_assigned', 0)}")
            print(f"   å¹³å‡åˆ†é…æ—¶é—´: {coordinator_stats.get('average_assignment_time', 0):.3f}s")
            
            # WorkerèŠ‚ç‚¹çŠ¶æ€
            print(f"ğŸ”§ WorkerèŠ‚ç‚¹:")
            for i, worker in enumerate(self.worker_nodes):
                stats = await worker.get_worker_stats()
                print(f"   Worker-{i+1}: {stats.get('worker_id', 'unknown')} "
                      f"({','.join(stats.get('fault_types', []))}) - "
                      f"çŠ¶æ€: {stats.get('status', 'unknown')}")
            
            print(f"\nğŸŒ é›†ç¾¤è®¿é—®åœ°å€:")
            print(f"   API Gateway: http://localhost:8000")
            print(f"   åè°ƒå™¨ç›‘æ§: Redis Key: vtox:coordinator:metrics")
            print(f"   é›†ç¾¤ç›‘æ§: Redis Key: vtox:cluster:metrics")
            
            print("="*80)
            
        except Exception as e:
            logger.error(f"âŒ æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€å¤±è´¥: {e}")
    
    async def stop_cluster(self):
        """åœæ­¢é›†ç¾¤"""
        try:
            logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢VTOXåˆ†å¸ƒå¼é›†ç¾¤...")
            
            self.is_running = False
            
            # åœæ­¢WorkerèŠ‚ç‚¹
            logger.info("ğŸ”§ åœæ­¢WorkerèŠ‚ç‚¹...")
            for worker in self.worker_nodes:
                try:
                    await worker.stop_worker()
                except Exception as e:
                    logger.warning(f"âš ï¸ åœæ­¢Workerå¤±è´¥: {worker.config.worker_id}")
            
            # åœæ­¢åè°ƒå™¨
            logger.info("ğŸ“Š åœæ­¢è¯Šæ–­åè°ƒå™¨...")
            if self.coordinator:
                await self.coordinator.stop_coordination()
            
            # åœæ­¢æœåŠ¡æ³¨å†Œè¡¨
            logger.info("ğŸ·ï¸ åœæ­¢æœåŠ¡æ³¨å†Œè¡¨...")
            if self.service_registry:
                await self.service_registry.stop_health_monitoring()
            
            # å…³é—­Redisè¿æ¥
            if self.redis_client:
                await self.redis_client.close()
            
            logger.info("âœ… VTOXåˆ†å¸ƒå¼é›†ç¾¤å·²å®Œå…¨åœæ­¢")
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢é›†ç¾¤å¤±è´¥: {e}")
    
    async def wait_for_shutdown(self):
        """ç­‰å¾…å…³é—­ä¿¡å·"""
        await self.shutdown_event.wait()

def setup_logging(level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('cluster.log')
        ]
    )

def signal_handler(cluster_manager: ClusterManager):
    """ä¿¡å·å¤„ç†å™¨"""
    def handler(signum, frame):
        logger.info(f"ğŸ”” æ¥æ”¶åˆ°åœæ­¢ä¿¡å·: {signum}")
        cluster_manager.shutdown_event.set()
    
    return handler

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="VTOX åˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤å¯åŠ¨å™¨")
    parser.add_argument("--mode", choices=["development", "testing", "production"], 
                       default="development", help="éƒ¨ç½²æ¨¡å¼")
    parser.add_argument("--workers", type=int, help="Workeræ•°é‡ (è¦†ç›–é»˜è®¤é…ç½®)")
    parser.add_argument("--redis-url", default="redis://localhost:6379", help="Redisè¿æ¥åœ°å€")
    parser.add_argument("--log-level", default="INFO", help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level)
    
    # åˆ›å»ºé›†ç¾¤ç®¡ç†å™¨
    cluster_manager = ClusterManager(args.mode)
    cluster_manager.redis_url = args.redis_url
    
    # è®¾ç½®ä¿¡å·å¤„ç†
    handler = signal_handler(cluster_manager)
    signal.signal(signal.SIGINT, handler)
    signal.signal(signal.SIGTERM, handler)
    
    try:
        # åˆå§‹åŒ–é›†ç¾¤
        if not await cluster_manager.initialize_cluster():
            logger.error("âŒ é›†ç¾¤åˆå§‹åŒ–å¤±è´¥")
            return 1
        
        # å¯åŠ¨é›†ç¾¤
        if not await cluster_manager.start_cluster(args.workers):
            logger.error("âŒ é›†ç¾¤å¯åŠ¨å¤±è´¥")
            return 1
        
        logger.info("ğŸ‰ é›†ç¾¤å¯åŠ¨å®Œæˆï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        
        # ç­‰å¾…å…³é—­ä¿¡å·
        await cluster_manager.wait_for_shutdown()
        
    except KeyboardInterrupt:
        logger.info("ğŸ”” æ¥æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·")
    except Exception as e:
        logger.error(f"âŒ é›†ç¾¤è¿è¡Œå¼‚å¸¸: {e}")
        return 1
    finally:
        # åœæ­¢é›†ç¾¤
        await cluster_manager.stop_cluster()
    
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main()))