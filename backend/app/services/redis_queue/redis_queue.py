import asyncio
import logging
from typing import Dict, Any, Callable, List
import json
from datetime import datetime
import redis.asyncio as redis
from ..simple_queue import TOPICS

logger = logging.getLogger(__name__)

class RedisQueue:
    """åŸºäºRedisçš„é˜Ÿåˆ—æœåŠ¡ï¼Œä¿æŒä¸SimpleQueueç›¸ä¼¼çš„æ¥å£"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        """åˆå§‹åŒ–Redisé˜Ÿåˆ—"""
        self.redis_url = redis_url
        self.redis_client = None
        self.handlers = {}
        self.consumer_tasks = []
        self.is_running = False
        self.connection_retry_count = 0
        self.max_connection_retries = 5
        self.connection_retry_delay = 2  # ç§’
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_sent': 0,
            'total_processed': 0,
            'total_errors': 0,
            'connection_retries': 0,
            'queue_lengths': {},
            'start_time': datetime.now()
        }
        
        logger.info(f"âœ… Redisé˜Ÿåˆ—æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œè¿æ¥åœ°å€: {redis_url}")

    async def connect(self):
        """å»ºç«‹Redisè¿æ¥ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        retry_count = 0
        while retry_count < self.max_connection_retries:
            try:
                self.redis_client = redis.from_url(
                    self.redis_url, 
                    decode_responses=True,
                    retry_on_timeout=True,
                    health_check_interval=30
                )
                await self.redis_client.ping()
                logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
                self.connection_retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°
                return True
            except Exception as e:
                retry_count += 1
                self.connection_retry_count += 1
                self.stats['connection_retries'] += 1
                logger.warning(f"âš ï¸  Redisè¿æ¥å¤±è´¥ (å°è¯• {retry_count}/{self.max_connection_retries}): {e}")
                
                if retry_count < self.max_connection_retries:
                    await asyncio.sleep(self.connection_retry_delay * retry_count)  # æŒ‡æ•°é€€é¿
                else:
                    logger.error(f"âŒ Redisè¿æ¥æœ€ç»ˆå¤±è´¥ï¼Œå·²å°è¯• {retry_count} æ¬¡")
                    return False

    async def send_message(self, topic: str, message: Dict[str, Any]) -> bool:
        """å‘é€æ¶ˆæ¯åˆ°Redisé˜Ÿåˆ—"""
        try:
            if not self.redis_client:
                logger.warning("âš ï¸  Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                # å°è¯•é‡æ–°è¿æ¥
                if not await self.connect():
                    return False
            
            # æ·»åŠ æ—¶é—´æˆ³å’Œå…ƒæ•°æ®
            enriched_message = {
                'timestamp': datetime.now().isoformat(),
                'data': message
            }
            
            # å°†æ¶ˆæ¯æ¨é€åˆ°Redisåˆ—è¡¨
            queue_key = f"queue:{topic}"
            await self.redis_client.lpush(queue_key, json.dumps(enriched_message))
            
            self.stats['total_sent'] += 1
            logger.debug(f"ğŸ“¤ æ¶ˆæ¯å·²å‘é€åˆ°Redisé˜Ÿåˆ— {topic}")
            return True
            
        except redis.ConnectionError as e:
            logger.error(f"âŒ Redisè¿æ¥é”™è¯¯: {e}")
            # å°è¯•é‡æ–°è¿æ¥
            if await self.connect():
                # é‡æ–°å°è¯•å‘é€æ¶ˆæ¯
                try:
                    queue_key = f"queue:{topic}"
                    await self.redis_client.lpush(queue_key, json.dumps(enriched_message))
                    self.stats['total_sent'] += 1
                    logger.debug(f"ğŸ“¤ æ¶ˆæ¯å·²é‡æ–°å‘é€åˆ°Redisé˜Ÿåˆ— {topic}")
                    return True
                except Exception as retry_error:
                    logger.error(f"âŒ é‡æ–°å‘é€æ¶ˆæ¯å¤±è´¥: {retry_error}")
            self.stats['total_errors'] += 1
            return False
        except Exception as e:
            logger.error(f"âŒ å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            self.stats['total_errors'] += 1
            return False

    def subscribe(self, topic: str, handler: Callable):
        """è®¢é˜…é˜Ÿåˆ—ä¸»é¢˜"""
        self.handlers[topic] = handler
        logger.info(f"ğŸ“¬ å·²è®¢é˜…é˜Ÿåˆ—ä¸»é¢˜: {topic}")

    async def start_consuming(self):
        """å¼€å§‹æ¶ˆè´¹æ‰€æœ‰é˜Ÿåˆ—"""
        if self.is_running:
            return
        
        if not self.redis_client:
            logger.warning("âš ï¸  Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return
            
        self.is_running = True
        logger.info("ğŸ”„ å¼€å§‹æ¶ˆè´¹Redisé˜Ÿåˆ—...")
        
        # ä¸ºæ¯ä¸ªè®¢é˜…çš„ä¸»é¢˜å¯åŠ¨æ¶ˆè´¹ä»»åŠ¡
        for topic in self.handlers.keys():
            task = asyncio.create_task(self._consume_queue(topic))
            self.consumer_tasks.append(task)
            logger.info(f"ğŸ¯ Redisé˜Ÿåˆ— {topic} æ¶ˆè´¹è€…å·²å¯åŠ¨")

    async def _consume_queue(self, topic: str):
        """æ¶ˆè´¹æŒ‡å®šé˜Ÿåˆ—çš„æ¶ˆæ¯"""
        handler = self.handlers.get(topic)
        if not handler:
            return
        
        queue_key = f"queue:{topic}"
        
        while self.is_running:
            try:
                # æ£€æŸ¥è¿æ¥çŠ¶æ€
                if not self.redis_client:
                    logger.warning("âš ï¸  Rediså®¢æˆ·ç«¯æœªè¿æ¥ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                    if not await self.connect():
                        await asyncio.sleep(1)
                        continue
                
                # ä»Redisé˜Ÿåˆ—ä¸­é˜»å¡å¼è·å–æ¶ˆæ¯
                result = await self.redis_client.brpop(queue_key, timeout=1)
                
                if result:
                    # è§£ææ¶ˆæ¯
                    _, message_json = result
                    message = json.loads(message_json)
                    
                    # è°ƒç”¨å¤„ç†å™¨
                    try:
                        if asyncio.iscoroutinefunction(handler):
                            await handler(message['data'])
                        else:
                            handler(message['data'])
                        
                        self.stats['total_processed'] += 1
                        logger.debug(f"âœ… å¤„ç†äº†æ¥è‡ª {topic} çš„æ¶ˆæ¯")
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                        self.stats['total_errors'] += 1
                else:
                    # è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯
                    await asyncio.sleep(0.01)
                    
            except redis.ConnectionError as e:
                logger.error(f"âŒ Redisè¿æ¥é”™è¯¯: {e}")
                # å°è¯•é‡æ–°è¿æ¥
                await self.connect()
                await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"âŒ å¤„ç†Redisé˜Ÿåˆ— {topic} æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                await asyncio.sleep(0.1)

    async def stop(self):
        """åœæ­¢æ¶ˆè´¹"""
        self.is_running = False
        
        # å–æ¶ˆæ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡
        for task in self.consumer_tasks:
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        
        # å…³é—­Redisè¿æ¥
        if self.redis_client:
            await self.redis_client.close()
            
        self.consumer_tasks.clear()
        logger.info("ğŸ›‘ Redisé˜Ÿåˆ—æ¶ˆè´¹å·²åœæ­¢")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ›´æ–°é˜Ÿåˆ—é•¿åº¦ç»Ÿè®¡
            for topic in self.handlers.keys():
                queue_key = f"queue:{topic}"
                if self.redis_client:
                    queue_length = self.redis_client.llen(queue_key)
                    self.stats['queue_lengths'][topic] = queue_length
        except Exception as e:
            logger.error(f"è·å–é˜Ÿåˆ—é•¿åº¦æ—¶å‡ºé”™: {e}")
        
        return {
            'type': 'redis_queue',
            'running': self.is_running,
            'uptime_seconds': (datetime.now() - self.stats['start_time']).total_seconds(),
            'total_sent': self.stats['total_sent'],
            'total_processed': self.stats['total_processed'],
            'total_errors': self.stats['total_errors'],
            'connection_retries': self.stats['connection_retries'],
            'queue_lengths': self.stats['queue_lengths'],
            'handlers_count': len(self.handlers)
        }

    async def clear_queue(self, topic: str):
        """æ¸…ç©ºæŒ‡å®šé˜Ÿåˆ—"""
        try:
            if not self.redis_client:
                logger.warning("âš ï¸  Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return
                
            queue_key = f"queue:{topic}"
            await self.redis_client.delete(queue_key)
            logger.info(f"ğŸ—‘ï¸  Redisé˜Ÿåˆ— {topic} å·²æ¸…ç©º")
        except Exception as e:
            logger.error(f"æ¸…ç©ºé˜Ÿåˆ— {topic} æ—¶å‡ºé”™: {e}")

    async def get_queue_length(self, topic: str) -> int:
        """è·å–é˜Ÿåˆ—é•¿åº¦"""
        try:
            if not self.redis_client:
                logger.warning("âš ï¸  Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return 0
                
            queue_key = f"queue:{topic}"
            return await self.redis_client.llen(queue_key)
        except Exception as e:
            logger.error(f"è·å–é˜Ÿåˆ— {topic} é•¿åº¦æ—¶å‡ºé”™: {e}")
            return 0

# å…¨å±€Redisé˜Ÿåˆ—å®ä¾‹
redis_queue = RedisQueue()

# ä¿æŒä¸TOPICSå¸¸é‡çš„å…¼å®¹æ€§
REDIS_TOPICS = TOPICS