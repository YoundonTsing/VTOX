"""
VTOX åˆ†å¸ƒå¼å·¥ä½œèŠ‚ç‚¹ (Worker Node)

æ ¸å¿ƒåŠŸèƒ½:
1. ç‹¬ç«‹æ•…éšœåˆ†æå¤„ç† - ä¸“æ³¨ç‰¹å®šæ•…éšœç±»å‹
2. è‡ªåŠ¨è´Ÿè½½æŠ¥å‘Š - å®æ—¶å‘åè°ƒå™¨æ±‡æŠ¥è´Ÿè½½çŠ¶æ€  
3. å¥åº·ç›‘æ§è‡ªæ£€ - ç›‘æ§è‡ªèº«èµ„æºä½¿ç”¨æƒ…å†µ
4. æ— ç¼é›†ç¾¤é›†æˆ - è‡ªåŠ¨æ³¨å†Œå’Œæ•…éšœè½¬ç§»

è®¾è®¡ç‰¹ç‚¹:
- è½»é‡çº§éƒ¨ç½² - å¯ç‹¬ç«‹å¯åŠ¨å’Œåœæ­¢
- ä¸“ä¸šåŒ–å¤„ç† - æ¯ä¸ªèŠ‚ç‚¹ä¸“æ³¨1-2ç§æ•…éšœç±»å‹
- å¼¹æ€§æ‰©å±• - æ”¯æŒåŠ¨æ€åŠ å…¥å’Œé€€å‡ºé›†ç¾¤
- å®Œå…¨å…¼å®¹ - å¤ç”¨ç°æœ‰æ•…éšœåˆ†æå™¨ä»£ç 
"""

import asyncio
import json
import logging
import time
import psutil
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import redis.asyncio as redis

from .service_registry import ServiceRegistry, ServiceClient, ServiceType, create_service_info
from ..redis_stream.distributed_diagnosis_stream import DistributedDiagnosisStream, FaultType

logger = logging.getLogger("worker-node")

@dataclass
class WorkerConfig:
    """WorkerèŠ‚ç‚¹é…ç½®"""
    worker_id: str
    host: str
    port: int
    fault_types: List[str]  # å¤„ç†çš„æ•…éšœç±»å‹
    max_concurrent_tasks: int = 10
    resource_monitoring: bool = True
    auto_scaling: bool = True
    redis_url: str = "redis://localhost:6379"

class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process(os.getpid())
        self.system_stats = {
            "cpu_usage": 0.0,
            "memory_usage": 0.0, 
            "disk_usage": 0.0,
            "network_io": 0,
            "last_updated": time.time()
        }
    
    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿèµ„æºæŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # è¿›ç¨‹èµ„æºä½¿ç”¨
            process_memory = self.process.memory_info().rss / 1024 / 1024  # MB
            process_cpu = self.process.cpu_percent()
            
            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_percent = disk.percent
            
            # ç½‘ç»œIO
            network = psutil.net_io_counters()
            network_total = network.bytes_sent + network.bytes_recv
            
            metrics = {
                "system_cpu_usage": cpu_percent,
                "system_memory_usage": memory_percent,
                "system_disk_usage": disk_percent,
                "process_memory_mb": process_memory,
                "process_cpu_usage": process_cpu,
                "network_io_bytes": network_total,
                "timestamp": time.time(),
                "healthy": self._calculate_health_status(cpu_percent, memory_percent)
            }
            
            self.system_stats.update(metrics)
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return {
                "system_cpu_usage": 0,
                "system_memory_usage": 0,
                "healthy": False,
                "error": str(e),
                "timestamp": time.time()
            }
    
    def _calculate_health_status(self, cpu_usage: float, memory_usage: float) -> bool:
        """è®¡ç®—å¥åº·çŠ¶æ€"""
        # ç®€å•å¥åº·æ£€æŸ¥ï¼šCPU < 90% ä¸” å†…å­˜ < 85%
        return cpu_usage < 90 and memory_usage < 85

class WorkerLoadReporter:
    """Workerè´Ÿè½½æŠ¥å‘Šå™¨"""
    
    def __init__(self, redis_client: redis.Redis, worker_id: str):
        self.redis = redis_client
        self.worker_id = worker_id
        self.load_key = "vtox:coordinator:worker_loads"
        
        # è´Ÿè½½ç»Ÿè®¡
        self.load_stats = {
            "current_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "total_processing_time": 0,
            "start_time": time.time(),
            "last_report_time": time.time()
        }
        
        # ä»»åŠ¡é˜Ÿåˆ—ç›‘æ§
        self.pending_messages = 0
        self.processing_times = []  # ä¿ç•™æœ€è¿‘100æ¬¡å¤„ç†æ—¶é—´
        
    async def report_load(self, resource_metrics: Dict[str, Any]):
        """æŠ¥å‘Šè´Ÿè½½çŠ¶æ€åˆ°åè°ƒå™¨"""
        try:
            current_time = time.time()
            
            # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
            avg_processing_time = (
                sum(self.processing_times) / len(self.processing_times)
                if self.processing_times else 100.0
            )
            
            # è®¡ç®—æˆåŠŸç‡
            total_tasks = self.load_stats["completed_tasks"] + self.load_stats["failed_tasks"]
            success_rate = (
                self.load_stats["completed_tasks"] / total_tasks
                if total_tasks > 0 else 1.0
            )
            
            # æ„å»ºè´Ÿè½½æŠ¥å‘Š
            load_report = {
                "worker_id": self.worker_id,
                "current_tasks": self.load_stats["current_tasks"],
                "pending_messages": self.pending_messages,
                "avg_processing_time": avg_processing_time,
                "cpu_usage": resource_metrics.get("system_cpu_usage", 0),
                "memory_usage": resource_metrics.get("system_memory_usage", 0),
                "success_rate": success_rate,
                "total_completed": self.load_stats["completed_tasks"],
                "total_failed": self.load_stats["failed_tasks"],
                "uptime": current_time - self.load_stats["start_time"],
                "last_updated": current_time,
                "healthy": resource_metrics.get("healthy", True)
            }
            
            # å‘é€åˆ°Redis
            await self.redis.hset(
                self.load_key,
                self.worker_id,
                json.dumps(load_report)
            )
            
            self.load_stats["last_report_time"] = current_time
            
            logger.debug(f"ğŸ“Š è´Ÿè½½æŠ¥å‘Šå·²å‘é€: ä»»åŠ¡{self.load_stats['current_tasks']} "
                        f"CPU{resource_metrics.get('system_cpu_usage', 0):.1f}% "
                        f"å†…å­˜{resource_metrics.get('system_memory_usage', 0):.1f}%")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€è´Ÿè½½æŠ¥å‘Šå¤±è´¥: {e}")
    
    def start_task(self):
        """å¼€å§‹å¤„ç†ä»»åŠ¡"""
        self.load_stats["current_tasks"] += 1
    
    def finish_task(self, processing_time: float, success: bool = True):
        """å®Œæˆä»»åŠ¡å¤„ç†"""
        self.load_stats["current_tasks"] = max(0, self.load_stats["current_tasks"] - 1)
        
        if success:
            self.load_stats["completed_tasks"] += 1
        else:
            self.load_stats["failed_tasks"] += 1
        
        # è®°å½•å¤„ç†æ—¶é—´
        self.processing_times.append(processing_time)
        if len(self.processing_times) > 100:
            self.processing_times.pop(0)
        
        self.load_stats["total_processing_time"] += processing_time
    
    def update_pending_messages(self, count: int):
        """æ›´æ–°å¾…å¤„ç†æ¶ˆæ¯æ•°"""
        self.pending_messages = count

class DistributedWorkerNode:
    """åˆ†å¸ƒå¼å·¥ä½œèŠ‚ç‚¹"""
    
    def __init__(self, config: WorkerConfig):
        self.config = config
        self.redis_client = None
        self.service_client: Optional[ServiceClient] = None
        
        # æ ¸å¿ƒç»„ä»¶
        self.diagnosis_stream: Optional[DistributedDiagnosisStream] = None
        self.resource_monitor = ResourceMonitor()
        self.load_reporter: Optional[WorkerLoadReporter] = None
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.worker_tasks = []
        
        # æ•…éšœç±»å‹æ˜ å°„
        self.fault_type_mapping = {
            "turn_fault": FaultType.TURN_FAULT,
            "insulation": FaultType.INSULATION,
            "bearing": FaultType.BEARING, 
            "eccentricity": FaultType.ECCENTRICITY,
            "broken_bar": FaultType.BROKEN_BAR
        }
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–WorkerèŠ‚ç‚¹"""
        try:
            # è¿æ¥Redis
            self.redis_client = redis.from_url(
                self.config.redis_url,
                decode_responses=True,
                retry_on_timeout=True,
                health_check_interval=30
            )
            await self.redis_client.ping()
            
            # åˆå§‹åŒ–åˆ†å¸ƒå¼è¯Šæ–­ç³»ç»Ÿ
            self.diagnosis_stream = DistributedDiagnosisStream(self.config.redis_url)
            await self.diagnosis_stream.connect()
            
            # åˆå§‹åŒ–è´Ÿè½½æŠ¥å‘Šå™¨
            self.load_reporter = WorkerLoadReporter(self.redis_client, self.config.worker_id)
            
            # æ³¨å†Œä¸ºæœåŠ¡
            await self._register_service()
            
            logger.info(f"âœ… WorkerèŠ‚ç‚¹åˆå§‹åŒ–æˆåŠŸ: {self.config.worker_id}")
            logger.info(f"   ğŸ¯ å¤„ç†æ•…éšœç±»å‹: {self.config.fault_types}")
            logger.info(f"   ğŸ“ æœåŠ¡åœ°å€: {self.config.host}:{self.config.port}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ WorkerèŠ‚ç‚¹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def _register_service(self):
        """æ³¨å†Œä¸ºé›†ç¾¤æœåŠ¡"""
        try:
            from .service_registry import get_service_registry
            
            # è·å–æœåŠ¡æ³¨å†Œè¡¨
            registry = await get_service_registry(self.redis_client)
            
            # åˆ›å»ºæœåŠ¡ä¿¡æ¯
            service_info = create_service_info(
                ServiceType.WORKER,
                f"VTOX Worker - {','.join(self.config.fault_types)}",
                self.config.host,
                self.config.port,
                self.config.fault_types,
                {
                    "worker_id": self.config.worker_id,
                    "max_concurrent_tasks": self.config.max_concurrent_tasks,
                    "resource_monitoring": self.config.resource_monitoring,
                    "auto_scaling": self.config.auto_scaling
                }
            )
            
            # åˆ›å»ºæœåŠ¡å®¢æˆ·ç«¯
            self.service_client = ServiceClient(registry, service_info)
            await self.service_client.start()
            
            logger.info(f"ğŸ·ï¸ æœåŠ¡æ³¨å†ŒæˆåŠŸ: {service_info.service_id}")
            
        except Exception as e:
            logger.error(f"âŒ æœåŠ¡æ³¨å†Œå¤±è´¥: {e}")
            raise
    
    async def start_worker(self) -> bool:
        """å¯åŠ¨WorkerèŠ‚ç‚¹"""
        try:
            if self.is_running:
                logger.warning("âš ï¸ WorkerèŠ‚ç‚¹å·²åœ¨è¿è¡Œä¸­")
                return True
            
            self.is_running = True
            
            # å¯åŠ¨å„ç§å·¥ä½œä»»åŠ¡
            self.worker_tasks = [
                asyncio.create_task(self._fault_processing_loop()),
                asyncio.create_task(self._resource_monitoring_loop()),
                asyncio.create_task(self._load_reporting_loop()),
                asyncio.create_task(self._health_check_loop())
            ]
            
            logger.info(f"ğŸš€ WorkerèŠ‚ç‚¹å¯åŠ¨æˆåŠŸ: {self.config.worker_id}")
            logger.info("   ğŸ”§ æ•…éšœå¤„ç†: å¯åŠ¨")
            logger.info("   ğŸ“Š èµ„æºç›‘æ§: å¯åŠ¨") 
            logger.info("   ğŸ“ˆ è´Ÿè½½æŠ¥å‘Š: å¯åŠ¨")
            logger.info("   ğŸ’“ å¥åº·æ£€æŸ¥: å¯åŠ¨")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨WorkerèŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    async def stop_worker(self):
        """åœæ­¢WorkerèŠ‚ç‚¹"""
        try:
            self.is_running = False
            
            # å–æ¶ˆæ‰€æœ‰å·¥ä½œä»»åŠ¡
            for task in self.worker_tasks:
                if not task.done():
                    task.cancel()
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            if self.worker_tasks:
                await asyncio.gather(*self.worker_tasks, return_exceptions=True)
            
            # æ³¨é”€æœåŠ¡
            if self.service_client:
                await self.service_client.stop()
            
            # æ¸…ç†Redisè¿æ¥
            if self.redis_client:
                await self.redis_client.close()
            
            logger.info(f"ğŸ›‘ WorkerèŠ‚ç‚¹å·²åœæ­¢: {self.config.worker_id}")
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢WorkerèŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _fault_processing_loop(self):
        """æ•…éšœå¤„ç†å¾ªç¯"""
        logger.info("ğŸ”§ å¯åŠ¨æ•…éšœå¤„ç†å¾ªç¯")
        
        # å­˜å‚¨æ¶ˆè´¹è€…ä»»åŠ¡
        consumer_tasks = []
        
        try:
            # ä¸ºæ¯ç§æ•…éšœç±»å‹å¯åŠ¨ä¸“é—¨çš„æ¶ˆè´¹è€…ï¼ˆåªå¯åŠ¨ä¸€æ¬¡ï¼‰
            for fault_type_str in self.config.fault_types:
                if fault_type_str in self.fault_type_mapping:
                    fault_type = self.fault_type_mapping[fault_type_str]
                    
                    # å¯åŠ¨æ•…éšœè¯Šæ–­æ¶ˆè´¹è€… (å¤ç”¨ç°æœ‰æ¶æ„)
                    consumer_id = f"{self.config.worker_id}_{fault_type_str}_consumer"
                    
                    # åˆ›å»ºæ¶ˆè´¹è€…ä»»åŠ¡
                    consumer_task = asyncio.create_task(
                        self._run_fault_consumer(fault_type, consumer_id)
                    )
                    consumer_tasks.append(consumer_task)
                    logger.debug(f"âœ… å¯åŠ¨æ¶ˆè´¹è€…: {consumer_id}")
            
            logger.info(f"âœ… å·²å¯åŠ¨{len(consumer_tasks)}ä¸ªæ•…éšœæ¶ˆè´¹è€…")
            
            # ç›‘æ§æ¶ˆè´¹è€…ä»»åŠ¡çŠ¶æ€
            while self.is_running:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å¼‚å¸¸ç»“æŸ
                for i, task in enumerate(consumer_tasks[:]):
                    if task.done():
                        fault_type_str = self.config.fault_types[i % len(self.config.fault_types)]
                        logger.warning(f"âš ï¸ æ¶ˆè´¹è€…ä»»åŠ¡å¼‚å¸¸ç»“æŸ: {fault_type_str}")
                        
                        # é‡æ–°å¯åŠ¨å¼‚å¸¸ç»“æŸçš„æ¶ˆè´¹è€…
                        if fault_type_str in self.fault_type_mapping:
                            fault_type = self.fault_type_mapping[fault_type_str]
                            consumer_id = f"{self.config.worker_id}_{fault_type_str}_consumer"
                            
                            new_task = asyncio.create_task(
                                self._run_fault_consumer(fault_type, consumer_id)
                            )
                            consumer_tasks[i] = new_task
                            logger.info(f"ğŸ”„ é‡æ–°å¯åŠ¨æ¶ˆè´¹è€…: {consumer_id}")
                
                # ç­‰å¾…60ç§’åå†æ¬¡æ£€æŸ¥
                await asyncio.sleep(60)
                
        except asyncio.CancelledError:
            logger.info("ğŸ›‘ æ•…éšœå¤„ç†å¾ªç¯è¢«å–æ¶ˆ")
            # å–æ¶ˆæ‰€æœ‰æ¶ˆè´¹è€…ä»»åŠ¡
            for task in consumer_tasks:
                if not task.done():
                    task.cancel()
        except Exception as e:
            logger.error(f"âŒ æ•…éšœå¤„ç†å¾ªç¯å¼‚å¸¸: {e}")
            # å–æ¶ˆæ‰€æœ‰æ¶ˆè´¹è€…ä»»åŠ¡
            for task in consumer_tasks:
                if not task.done():
                    task.cancel()
    
    async def _run_fault_consumer(self, fault_type: FaultType, consumer_id: str):
        """è¿è¡Œæ•…éšœæ¶ˆè´¹è€…"""
        try:
            while self.is_running:
                start_time = time.time()
                
                # å¼€å§‹å¤„ç†ä»»åŠ¡
                self.load_reporter.start_task()
                
                try:
                    # è°ƒç”¨ç°æœ‰çš„æ•…éšœè¯Šæ–­æ¶ˆè´¹è€… (ä¿æŒå…¼å®¹æ€§)
                    await self.diagnosis_stream.start_fault_diagnosis_consumer(
                        fault_type, consumer_id
                    )
                    
                    # å¤„ç†æˆåŠŸ
                    processing_time = time.time() - start_time
                    self.load_reporter.finish_task(processing_time, success=True)
                    
                except Exception as e:
                    # å¤„ç†å¤±è´¥
                    processing_time = time.time() - start_time
                    self.load_reporter.finish_task(processing_time, success=False)
                    logger.error(f"âŒ æ•…éšœå¤„ç†å¤±è´¥: {fault_type.value} - {e}")
                    
                    # çŸ­æš‚ä¼‘æ¯åé‡è¯•
                    await asyncio.sleep(1)
                
        except asyncio.CancelledError:
            logger.info(f"ğŸ›‘ æ•…éšœæ¶ˆè´¹è€…åœæ­¢: {consumer_id}")
        except Exception as e:
            logger.error(f"âŒ æ•…éšœæ¶ˆè´¹è€…å¼‚å¸¸: {consumer_id} - {e}")
    
    async def _resource_monitoring_loop(self):
        """èµ„æºç›‘æ§å¾ªç¯"""
        logger.info("ğŸ“Š å¯åŠ¨èµ„æºç›‘æ§å¾ªç¯")
        
        while self.is_running:
            try:
                if self.config.resource_monitoring:
                    # è·å–ç³»ç»Ÿèµ„æºæŒ‡æ ‡
                    metrics = self.resource_monitor.get_system_metrics()
                    
                    # æ›´æ–°æœåŠ¡å…ƒæ•°æ®
                    if self.service_client:
                        self.service_client.update_metadata({
                            "cpu_usage": metrics.get("system_cpu_usage", 0),
                            "memory_usage": metrics.get("system_memory_usage", 0),
                            "healthy": metrics.get("healthy", True),
                            "last_updated": metrics.get("timestamp", time.time())
                        })
                    
                    # æ£€æŸ¥èµ„æºä½¿ç”¨æ˜¯å¦è¿‡é«˜
                    if metrics.get("system_cpu_usage", 0) > 90:
                        logger.warning(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics['system_cpu_usage']:.1f}%")
                    
                    if metrics.get("system_memory_usage", 0) > 85:
                        logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['system_memory_usage']:.1f}%")
                
                await asyncio.sleep(10)  # æ¯10ç§’ç›‘æ§ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ èµ„æºç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    async def _load_reporting_loop(self):
        """è´Ÿè½½æŠ¥å‘Šå¾ªç¯"""
        logger.info("ğŸ“ˆ å¯åŠ¨è´Ÿè½½æŠ¥å‘Šå¾ªç¯")
        
        while self.is_running:
            try:
                # è·å–èµ„æºæŒ‡æ ‡
                resource_metrics = self.resource_monitor.get_system_metrics()
                
                # æ›´æ–°å¾…å¤„ç†æ¶ˆæ¯æ•° (ä»Redis Streamè·å–)
                await self._update_pending_messages()
                
                # å‘é€è´Ÿè½½æŠ¥å‘Š
                await self.load_reporter.report_load(resource_metrics)
                
                await asyncio.sleep(15)  # æ¯15ç§’æŠ¥å‘Šä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ è´Ÿè½½æŠ¥å‘Šå¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    async def _update_pending_messages(self):
        """æ›´æ–°å¾…å¤„ç†æ¶ˆæ¯æ•°é‡"""
        try:
            total_pending = 0
            
            # æ£€æŸ¥æ¯ä¸ªæ•…éšœç±»å‹çš„æ¶ˆè´¹è€…ç»„å¾…å¤„ç†æ¶ˆæ¯
            for fault_type_str in self.config.fault_types:
                if fault_type_str in self.fault_type_mapping:
                    group_name = f"{fault_type_str}_diagnosis_group"
                    
                    try:
                        # è·å–æ¶ˆè´¹è€…ç»„ä¿¡æ¯ (éœ€è¦Redis Streamæ”¯æŒ)
                        # è¿™é‡Œå…ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…éœ€è¦ä»Redis Streamè·å–
                        pending_count = await self._get_consumer_group_pending(group_name)
                        total_pending += pending_count
                        
                    except Exception as e:
                        logger.debug(f"è·å–{group_name}å¾…å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            
            self.load_reporter.update_pending_messages(total_pending)
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¾…å¤„ç†æ¶ˆæ¯æ•°å¤±è´¥: {e}")
    
    async def _get_consumer_group_pending(self, group_name: str) -> int:
        """è·å–æ¶ˆè´¹è€…ç»„å¾…å¤„ç†æ¶ˆæ¯æ•°"""
        try:
            # ä½¿ç”¨XPENDINGå‘½ä»¤è·å–å¾…å¤„ç†æ¶ˆæ¯æ•°
            pending_info = await self.redis_client.xpending(
                "motor_raw_data",  # Streamåç§°
                group_name
            )
            
            if pending_info:
                return pending_info[0]  # æ€»å¾…å¤„ç†æ¶ˆæ¯æ•°
            
            return 0
            
        except Exception as e:
            logger.debug(f"è·å–æ¶ˆè´¹è€…ç»„å¾…å¤„ç†æ¶ˆæ¯å¤±è´¥: {group_name} - {e}")
            return 0
    
    async def _health_check_loop(self):
        """å¥åº·æ£€æŸ¥å¾ªç¯"""
        logger.info("ğŸ’“ å¯åŠ¨å¥åº·æ£€æŸ¥å¾ªç¯")
        
        while self.is_running:
            try:
                # æ£€æŸ¥Redisè¿æ¥
                await self.redis_client.ping()
                
                # æ£€æŸ¥è¯Šæ–­ç³»ç»Ÿè¿æ¥
                if self.diagnosis_stream and self.diagnosis_stream.redis_client:
                    await self.diagnosis_stream.redis_client.ping()
                
                # æ£€æŸ¥èµ„æºçŠ¶æ€
                metrics = self.resource_monitor.get_system_metrics()
                if not metrics.get("healthy", True):
                    logger.warning("âš ï¸ WorkerèŠ‚ç‚¹èµ„æºçŠ¶æ€ä¸å¥åº·")
                
                await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                await asyncio.sleep(10)
    
    async def get_worker_stats(self) -> Dict[str, Any]:
        """è·å–Workerç»Ÿè®¡ä¿¡æ¯"""
        try:
            current_time = time.time()
            uptime = current_time - self.load_reporter.load_stats["start_time"]
            
            # è·å–èµ„æºæŒ‡æ ‡
            resource_metrics = self.resource_monitor.get_system_metrics()
            
            # è·å–è´Ÿè½½ç»Ÿè®¡
            load_stats = self.load_reporter.load_stats
            
            return {
                "worker_id": self.config.worker_id,
                "status": "running" if self.is_running else "stopped",
                "uptime_seconds": uptime,
                "fault_types": self.config.fault_types,
                "current_tasks": load_stats["current_tasks"],
                "completed_tasks": load_stats["completed_tasks"],
                "failed_tasks": load_stats["failed_tasks"],
                "pending_messages": self.load_reporter.pending_messages,
                "resource_metrics": resource_metrics,
                "service_registered": self.service_client is not None,
                "timestamp": current_time
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–Workerç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}


# ä¾¿æ·å‡½æ•°
def create_worker_config(worker_id: str, host: str, port: int, 
                        fault_types: List[str], **kwargs) -> WorkerConfig:
    """åˆ›å»ºWorkeré…ç½®"""
    return WorkerConfig(
        worker_id=worker_id,
        host=host,
        port=port,
        fault_types=fault_types,
        **kwargs
    )

async def start_worker_node(config: WorkerConfig) -> DistributedWorkerNode:
    """å¯åŠ¨WorkerèŠ‚ç‚¹"""
    worker = DistributedWorkerNode(config)
    
    if await worker.initialize():
        if await worker.start_worker():
            return worker
        else:
            raise Exception("å¯åŠ¨Workerå¤±è´¥")
    else:
        raise Exception("åˆå§‹åŒ–Workerå¤±è´¥")