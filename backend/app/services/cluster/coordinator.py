"""
VTOX åˆ†å¸ƒå¼è¯Šæ–­åè°ƒå™¨

æ ¸å¿ƒåŠŸèƒ½:
1. æ™ºèƒ½ä»»åŠ¡åˆ†å‘ - åŸºäºWorkerèƒ½åŠ›å’Œè´Ÿè½½çŠ¶æ€
2. åŠ¨æ€è´Ÿè½½å‡è¡¡ - å®æ—¶è°ƒæ•´ä»»åŠ¡åˆ†é…ç­–ç•¥
3. æ•…éšœè½¬ç§»å¤„ç† - WorkerèŠ‚ç‚¹æ•…éšœæ—¶è‡ªåŠ¨é‡æ–°åˆ†é…
4. æ€§èƒ½ç›‘æ§ç»Ÿè®¡ - æ”¶é›†å’Œåˆ†æç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
"""

import asyncio
import json
import logging
import time
import random
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import redis.asyncio as redis
from collections import defaultdict, deque

from .service_registry import ServiceRegistry, ServiceType, ServiceStatus, get_service_registry

logger = logging.getLogger("diagnosis-coordinator")

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

class LoadBalanceStrategy(Enum):
    """è´Ÿè½½å‡è¡¡ç­–ç•¥"""
    ROUND_ROBIN = "round_robin"
    LEAST_CONNECTIONS = "least_connections" 
    SMART_PREDICTION = "smart_prediction"

@dataclass
class TaskInfo:
    """ä»»åŠ¡ä¿¡æ¯"""
    task_id: str
    fault_type: str
    vehicle_id: str
    priority: TaskPriority
    data_size: int
    estimated_processing_time: float
    created_at: float
    assigned_worker: Optional[str] = None

@dataclass 
class WorkerLoad:
    """Workerè´Ÿè½½ä¿¡æ¯"""
    worker_id: str
    service_name: str
    host: str
    port: int
    capabilities: List[str]
    current_tasks: int
    pending_messages: int
    avg_processing_time: float
    cpu_usage: float
    memory_usage: float
    success_rate: float
    last_updated: float
    health_score: float = 1.0

class IntelligentLoadBalancer:
    """æ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self):
        self.strategy = LoadBalanceStrategy.SMART_PREDICTION
        self.performance_weights = {
            "response_time": 0.3,
            "success_rate": 0.25, 
            "cpu_usage": 0.2,
            "memory_usage": 0.15,
            "queue_length": 0.1
        }
    
    def calculate_worker_score(self, worker_load: WorkerLoad, task_info: TaskInfo) -> float:
        """è®¡ç®—Workeré€‚åˆåº¦è¯„åˆ†"""
        try:
            # åŸºç¡€èƒ½åŠ›æ£€æŸ¥
            if task_info.fault_type not in worker_load.capabilities:
                return 0.0
            
            # å¥åº·çŠ¶æ€æ£€æŸ¥
            if worker_load.health_score < 0.5:
                return 0.0
            
            # å¤šç»´åº¦è¯„åˆ†
            scores = {}
            
            # 1. å“åº”æ—¶é—´è¯„åˆ† (è¶Šä½è¶Šå¥½)
            normalized_time = min(worker_load.avg_processing_time / 1000.0, 1.0)
            scores["response_time"] = 1.0 - normalized_time
            
            # 2. æˆåŠŸç‡è¯„åˆ†
            scores["success_rate"] = worker_load.success_rate
            
            # 3. CPUä½¿ç”¨ç‡è¯„åˆ† (è¶Šä½è¶Šå¥½)  
            scores["cpu_usage"] = 1.0 - min(worker_load.cpu_usage / 100.0, 1.0)
            
            # 4. å†…å­˜ä½¿ç”¨ç‡è¯„åˆ† (è¶Šä½è¶Šå¥½)
            scores["memory_usage"] = 1.0 - min(worker_load.memory_usage / 100.0, 1.0)
            
            # 5. é˜Ÿåˆ—é•¿åº¦è¯„åˆ† (è¶ŠçŸ­è¶Šå¥½)
            max_queue = 100
            normalized_queue = min(worker_load.pending_messages / max_queue, 1.0)
            scores["queue_length"] = 1.0 - normalized_queue
            
            # åŠ æƒç»¼åˆè¯„åˆ†
            total_score = sum(
                scores[metric] * weight 
                for metric, weight in self.performance_weights.items()
            )
            
            # åº”ç”¨å¥åº·çŠ¶æ€æƒé‡
            final_score = total_score * worker_load.health_score
            return final_score
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—Workerè¯„åˆ†å¤±è´¥: {e}")
            return 0.0
    
    def select_best_worker(self, available_workers: List[WorkerLoad],
                          task_info: TaskInfo) -> Optional[WorkerLoad]:
        """é€‰æ‹©æœ€ä½³Worker"""
        if not available_workers:
            return None
        
        try:
            # è¿‡æ»¤æœ‰èƒ½åŠ›å¤„ç†è¯¥æ•…éšœç±»å‹çš„Worker
            capable_workers = [
                worker for worker in available_workers
                if task_info.fault_type in worker.capabilities
            ]
            
            if not capable_workers:
                logger.warning(f"âš ï¸ æ²¡æœ‰Workerèƒ½å¤„ç†æ•…éšœç±»å‹: {task_info.fault_type}")
                return None
            
            if self.strategy == LoadBalanceStrategy.SMART_PREDICTION:
                # æ™ºèƒ½é¢„æµ‹ç­–ç•¥
                worker_scores = []
                for worker in capable_workers:
                    score = self.calculate_worker_score(worker, task_info)
                    worker_scores.append((worker, score))
                
                # é€‰æ‹©è¯„åˆ†æœ€é«˜çš„Worker
                best_worker = max(worker_scores, key=lambda x: x[1])
                logger.debug(f"ğŸ¯ é€‰æ‹©Worker: {best_worker[0].service_name} (è¯„åˆ†: {best_worker[1]:.3f})")
                return best_worker[0]
            
            elif self.strategy == LoadBalanceStrategy.LEAST_CONNECTIONS:
                return min(capable_workers, key=lambda w: w.current_tasks)
            
            else:
                return random.choice(capable_workers)
                
        except Exception as e:
            logger.error(f"âŒ é€‰æ‹©Workerå¤±è´¥: {e}")
            return random.choice(capable_workers) if capable_workers else None

class DiagnosisCoordinator:
    """åˆ†å¸ƒå¼è¯Šæ–­åè°ƒå™¨"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.registry: Optional[ServiceRegistry] = None
        self.load_balancer = IntelligentLoadBalancer()
        
        # Redisé”®å®šä¹‰
        self.task_queue_key = "vtox:coordinator:tasks"
        self.worker_loads_key = "vtox:coordinator:worker_loads"
        self.assignments_key = "vtox:coordinator:assignments"
        
        # åè°ƒå™¨çŠ¶æ€
        self.is_running = False
        self.coordination_tasks = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "tasks_assigned": 0,
            "tasks_completed": 0,
            "tasks_failed": 0,
            "average_assignment_time": 0,
            "start_time": None
        }
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–åè°ƒå™¨"""
        try:
            self.registry = await get_service_registry(self.redis)
            self.registry.add_event_listener("service_registered", self._on_service_registered)
            self.registry.add_event_listener("service_deregistered", self._on_service_deregistered)
            
            logger.info("âœ… è¯Šæ–­åè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åè°ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def start_coordination(self) -> bool:
        """å¯åŠ¨åè°ƒæœåŠ¡"""
        try:
            if self.is_running:
                return True
            
            self.is_running = True
            self.stats["start_time"] = time.time()
            
            # å¯åŠ¨ç›‘æ§ä»»åŠ¡
            self.coordination_tasks = [
                asyncio.create_task(self._task_assignment_loop()),
                asyncio.create_task(self._worker_monitoring_loop()),
                asyncio.create_task(self._performance_monitoring_loop())
            ]
            
            logger.info("ğŸš€ åˆ†å¸ƒå¼è¯Šæ–­åè°ƒå™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨åè°ƒå™¨å¤±è´¥: {e}")
            return False
    
    async def stop_coordination(self):
        """åœæ­¢åè°ƒæœåŠ¡"""
        try:
            self.is_running = False
            
            for task in self.coordination_tasks:
                if not task.done():
                    task.cancel()
            
            if self.coordination_tasks:
                await asyncio.gather(*self.coordination_tasks, return_exceptions=True)
            
            logger.info("ğŸ›‘ åˆ†å¸ƒå¼è¯Šæ–­åè°ƒå™¨å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢åè°ƒå™¨å¤±è´¥: {e}")
    
    async def submit_task(self, fault_type: str, vehicle_id: str,
                         message_data: Dict[str, Any],
                         priority: TaskPriority = TaskPriority.NORMAL) -> str:
        """æäº¤è¯Šæ–­ä»»åŠ¡"""
        try:
            task_id = f"task_{int(time.time() * 1000)}_{random.randint(1000, 9999)}"
            
            task_info = TaskInfo(
                task_id=task_id,
                fault_type=fault_type,
                vehicle_id=vehicle_id,
                priority=priority,
                data_size=len(json.dumps(message_data)),
                estimated_processing_time=self._estimate_processing_time(fault_type, message_data),
                created_at=time.time()
            )
            
            task_data = {
                **task_info.__dict__,
                "message_data": message_data,
                "priority": priority.value
            }
            
            await self.redis.lpush(
                self.task_queue_key,
                json.dumps(task_data)
            )
            
            logger.debug(f"ğŸ“‹ ä»»åŠ¡å·²æäº¤: {task_id} ({fault_type})")
            return task_id
            
        except Exception as e:
            logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _task_assignment_loop(self):
        """ä»»åŠ¡åˆ†é…å¾ªç¯"""
        logger.info("ğŸ“‹ å¯åŠ¨ä»»åŠ¡åˆ†é…å¾ªç¯")
        
        while self.is_running:
            try:
                task_data = await self.redis.brpop(self.task_queue_key, timeout=1)
                if task_data:
                    _, task_json = task_data
                    await self._assign_task(json.loads(task_json))
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ ä»»åŠ¡åˆ†é…å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(1)
    
    async def _assign_task(self, task_data: Dict[str, Any]):
        """åˆ†é…å•ä¸ªä»»åŠ¡"""
        try:
            start_time = time.time()
            
            task_info = TaskInfo(
                task_id=task_data["task_id"],
                fault_type=task_data["fault_type"],
                vehicle_id=task_data["vehicle_id"],
                priority=TaskPriority(task_data["priority"]),
                data_size=task_data["data_size"],
                estimated_processing_time=task_data["estimated_processing_time"],
                created_at=task_data["created_at"]
            )
            
            # è·å–å¯ç”¨Worker
            available_workers = await self._get_available_workers()
            
            if not available_workers:
                await self.redis.lpush(self.task_queue_key, json.dumps(task_data))
                logger.warning(f"âš ï¸ æ²¡æœ‰å¯ç”¨Workerï¼Œä»»åŠ¡é‡æ–°å…¥é˜Ÿ: {task_info.task_id}")
                return
            
            # é€‰æ‹©æœ€ä½³Worker
            selected_worker = self.load_balancer.select_best_worker(
                available_workers, task_info
            )
            
            if not selected_worker:
                logger.error(f"âŒ æ— æ³•ä¸ºä»»åŠ¡é€‰æ‹©Worker: {task_info.task_id}")
                return
            
            # å‘é€ä»»åŠ¡åˆ°Redis Stream (å…¼å®¹ç°æœ‰æ¶æ„)
            await self._dispatch_to_redis_stream(task_data, selected_worker)
            
            # æ›´æ–°ç»Ÿè®¡
            assignment_time = time.time() - start_time
            self.stats["tasks_assigned"] += 1
            self.stats["average_assignment_time"] = (
                (self.stats["average_assignment_time"] * (self.stats["tasks_assigned"] - 1) + assignment_time) /
                self.stats["tasks_assigned"]
            )
            
            logger.debug(f"âœ… ä»»åŠ¡åˆ†é…æˆåŠŸ: {task_info.task_id} â†’ {selected_worker.service_name}")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡åˆ†é…å¤±è´¥: {e}")
    
    async def _dispatch_to_redis_stream(self, task_data: Dict[str, Any], 
                                      selected_worker: WorkerLoad):
        """å°†ä»»åŠ¡åˆ†å‘åˆ°Redis Stream (ä¿æŒå…¼å®¹æ€§)"""
        try:
            # æ„å»ºä¸ç°æœ‰æ¶æ„å…¼å®¹çš„æ¶ˆæ¯æ ¼å¼
            message = {
                "vehicle_id": task_data["vehicle_id"],
                "timestamp": datetime.now().isoformat(),
                "sensor_data": json.dumps(task_data["message_data"]),
                "metadata": json.dumps({
                    "coordinator_assigned": True,
                    "assigned_worker": selected_worker.worker_id,
                    "task_id": task_data["task_id"],
                    "priority": task_data["priority"]
                }),
                "data_type": "motor_sensor_data"
            }
            
            # å‘å¸ƒåˆ°åŸå§‹æ•°æ®æµ (ç°æœ‰æ¶æ„ä¼šè‡ªåŠ¨å¤„ç†)
            message_id = await self.redis.xadd(
                "motor_raw_data",  # ä½¿ç”¨ç°æœ‰çš„Streamåç§°
                message,
                maxlen=50000
            )
            
            logger.debug(f"ğŸ“¤ ä»»åŠ¡å·²å‘é€åˆ°Redis Stream: {message_id}")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€ä»»åŠ¡åˆ°Redis Streamå¤±è´¥: {e}")
            raise
    
    async def _get_available_workers(self) -> List[WorkerLoad]:
        """è·å–å¯ç”¨çš„Workeråˆ—è¡¨"""
        try:
            worker_services = await self.registry.get_services(
                service_type=ServiceType.WORKER,
                status=ServiceStatus.HEALTHY
            )
            
            worker_loads = []
            current_time = time.time()
            
            for service in worker_services:
                try:
                    load_data = await self.redis.hget(self.worker_loads_key, service.service_id)
                    
                    if load_data:
                        load_info = json.loads(load_data)
                        if current_time - load_info["last_updated"] < 60:
                            worker_load = WorkerLoad(
                                worker_id=service.service_id,
                                service_name=service.service_name,
                                host=service.host,
                                port=service.port,
                                capabilities=service.capabilities,
                                current_tasks=load_info.get("current_tasks", 0),
                                pending_messages=load_info.get("pending_messages", 0),
                                avg_processing_time=load_info.get("avg_processing_time", 100),
                                cpu_usage=load_info.get("cpu_usage", 50),
                                memory_usage=load_info.get("memory_usage", 50),
                                success_rate=load_info.get("success_rate", 0.95),
                                last_updated=load_info["last_updated"],
                                health_score=self._calculate_health_score(load_info)
                            )
                            worker_loads.append(worker_load)
                    else:
                        # ä½¿ç”¨é»˜è®¤å€¼
                        worker_load = WorkerLoad(
                            worker_id=service.service_id,
                            service_name=service.service_name,
                            host=service.host,
                            port=service.port,
                            capabilities=service.capabilities,
                            current_tasks=0,
                            pending_messages=0,
                            avg_processing_time=100,
                            cpu_usage=30,
                            memory_usage=40,
                            success_rate=1.0,
                            last_updated=current_time,
                            health_score=1.0
                        )
                        worker_loads.append(worker_load)
                
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–Workerè´Ÿè½½å¤±è´¥: {service.service_id} - {e}")
                    continue
            
            return worker_loads
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¯ç”¨Workerå¤±è´¥: {e}")
            return []
    
    def _calculate_health_score(self, load_info: Dict[str, Any]) -> float:
        """è®¡ç®—Workerå¥åº·è¯„åˆ†"""
        try:
            health_factors = {
                "cpu_ok": 1.0 if load_info.get("cpu_usage", 0) < 80 else 0.5,
                "memory_ok": 1.0 if load_info.get("memory_usage", 0) < 80 else 0.5,
                "success_rate": load_info.get("success_rate", 0.95),
                "response_time": 1.0 if load_info.get("avg_processing_time", 100) < 200 else 0.8
            }
            
            weights = {"cpu_ok": 0.25, "memory_ok": 0.25, "success_rate": 0.3, "response_time": 0.2}
            health_score = sum(health_factors[k] * weights[k] for k in weights)
            
            return max(0.0, min(1.0, health_score))
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—å¥åº·è¯„åˆ†å¤±è´¥: {e}")
            return 0.5
    
    def _estimate_processing_time(self, fault_type: str, message_data: Dict[str, Any]) -> float:
        """ä¼°ç®—å¤„ç†æ—¶é—´"""
        try:
            base_times = {
                "turn_fault": 50, "insulation": 40, "bearing": 60,
                "eccentricity": 45, "broken_bar": 55
            }
            
            base_time = base_times.get(fault_type, 50)
            data_size = len(json.dumps(message_data))
            size_factor = 1.0 + (data_size / 10000)
            
            return base_time * size_factor
            
        except Exception as e:
            return 100.0
    
    async def _worker_monitoring_loop(self):
        """Workerç›‘æ§å¾ªç¯"""
        while self.is_running:
            try:
                await self._update_worker_loads()
                await asyncio.sleep(10)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ Workerç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    async def _update_worker_loads(self):
        """æ›´æ–°Workerè´Ÿè½½ä¿¡æ¯"""
        try:
            worker_services = await self.registry.get_services(
                service_type=ServiceType.WORKER,
                status=ServiceStatus.HEALTHY
            )
            
            for service in worker_services:
                try:
                    # æ¨¡æ‹Ÿè´Ÿè½½æ•°æ®ï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦Workeræä¾›è´Ÿè½½API
                    load_info = {
                        "worker_id": service.service_id,
                        "current_tasks": random.randint(0, 10),
                        "pending_messages": random.randint(0, 50),
                        "avg_processing_time": random.uniform(50, 200),
                        "cpu_usage": random.uniform(20, 80),
                        "memory_usage": random.uniform(30, 70),
                        "success_rate": random.uniform(0.90, 1.0),
                        "last_updated": time.time()
                    }
                    
                    await self.redis.hset(
                        self.worker_loads_key,
                        service.service_id,
                        json.dumps(load_info)
                    )
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ æ›´æ–°Workerè´Ÿè½½å¤±è´¥: {service.service_id}")
                    
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°Workerè´Ÿè½½ä¿¡æ¯å¤±è´¥: {e}")
    
    async def _performance_monitoring_loop(self):
        """æ€§èƒ½ç›‘æ§å¾ªç¯"""
        while self.is_running:
            try:
                await self._collect_performance_metrics()
                await asyncio.sleep(30)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(10)
    
    async def _collect_performance_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            current_time = time.time()
            queue_length = await self.redis.llen(self.task_queue_key)
            
            worker_services = await self.registry.get_services(ServiceType.WORKER)
            healthy_workers = len([s for s in worker_services if s.status == ServiceStatus.HEALTHY])
            
            metrics = {
                "timestamp": current_time,
                "queue_length": queue_length,
                "total_workers": len(worker_services),
                "healthy_workers": healthy_workers,
                "tasks_assigned": self.stats["tasks_assigned"],
                "average_assignment_time": self.stats["average_assignment_time"]
            }
            
            await self.redis.xadd(
                "vtox:coordinator:metrics",
                {k: str(v) for k, v in metrics.items()},
                maxlen=1000
            )
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    async def _on_service_registered(self, service_data: Dict[str, Any]):
        """æœåŠ¡æ³¨å†Œäº‹ä»¶å¤„ç†"""
        if service_data.get("service_type") == ServiceType.WORKER.value:
            logger.info(f"ğŸ†• æ–°WorkeræœåŠ¡æ³¨å†Œ: {service_data['service_name']}")
    
    async def _on_service_deregistered(self, service_data: Dict[str, Any]):
        """æœåŠ¡æ³¨é”€äº‹ä»¶å¤„ç†"""
        if service_data.get("service_type") == ServiceType.WORKER.value:
            logger.info(f"ğŸ‘‹ WorkeræœåŠ¡æ³¨é”€: {service_data['service_name']}")
    
    async def get_coordinator_stats(self) -> Dict[str, Any]:
        """è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            current_time = time.time()
            uptime = current_time - self.stats["start_time"] if self.stats["start_time"] else 0
            
            # è·å–å½“å‰é˜Ÿåˆ—çŠ¶æ€
            queue_length = await self.redis.llen(self.task_queue_key)
            
            # è·å–WorkerçŠ¶æ€
            worker_services = await self.registry.get_services(ServiceType.WORKER)
            healthy_workers = len([s for s in worker_services if s.status == ServiceStatus.HEALTHY])
            
            return {
                "coordinator_status": "running" if self.is_running else "stopped",
                "uptime_seconds": uptime,
                "tasks_assigned": self.stats["tasks_assigned"],
                "tasks_completed": self.stats["tasks_completed"],
                "tasks_failed": self.stats["tasks_failed"],
                "average_assignment_time": self.stats["average_assignment_time"],
                "current_queue_length": queue_length,
                "total_workers": len(worker_services),
                "healthy_workers": healthy_workers,
                "load_balance_strategy": self.load_balancer.strategy.value,
                "timestamp": current_time
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–åè°ƒå™¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€åè°ƒå™¨å®ä¾‹
diagnosis_coordinator: Optional[DiagnosisCoordinator] = None

async def get_diagnosis_coordinator(redis_client: redis.Redis) -> DiagnosisCoordinator:
    """è·å–å…¨å±€åè°ƒå™¨å®ä¾‹"""
    global diagnosis_coordinator
    
    if diagnosis_coordinator is None:
        diagnosis_coordinator = DiagnosisCoordinator(redis_client)
        await diagnosis_coordinator.initialize()
    
    return diagnosis_coordinator