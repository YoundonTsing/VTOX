#!/usr/bin/env python3
"""
Redis Streamåˆ°å‰ç«¯æ¡¥æ¥ç»„ä»¶
è½»é‡çº§æ•°æ®è½¬å‘ï¼Œä¸è¿›è¡Œå¤æ‚è®¡ç®—ï¼Œé¿å…è´Ÿè½½è¿‡é«˜
æ”¯æŒç¼“å­˜ä¼˜åŒ–æ¨¡å¼ï¼Œè§£å†³æ¶ˆæ¯ä¸¢å¤±é—®é¢˜
"""

import asyncio
import json
import logging
from typing import Dict, Any, Optional, cast
from datetime import datetime
import redis.asyncio as redis

logger = logging.getLogger(__name__)

class StreamToFrontendBridge:
    """
    è½»é‡çº§æ¡¥æ¥ç»„ä»¶ï¼šå°†Redis Streamå¤„ç†ç»“æœè½¬å‘åˆ°WebSocketå‰ç«¯
    
    è®¾è®¡åŸåˆ™ï¼š
    - åªè´Ÿè´£æ•°æ®è½¬å‘ï¼Œä¸è¿›è¡Œä»»ä½•è®¡ç®—
    - ä¿æŒè½»é‡çº§ï¼Œé¿å…ç³»ç»Ÿè´Ÿè½½è¿‡é«˜
    - ç¡®ä¿å‰ç«¯æ”¶åˆ°å®Œæ•´çš„vehicle_idå’Œhealth_scoreæ•°æ®
    - æ”¯æŒç¼“å­˜ä¼˜åŒ–æ¨¡å¼ï¼Œå¤§å¹…å‡å°‘æ¶ˆæ¯ä¸¢å¤±
    """
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_url = redis_url
        self.redis_client: Optional[redis.Redis] = None
        self.websocket_manager = None
        self.is_running = False
        self.is_monitoring = False  # å¢åŠ ç›‘æ§çŠ¶æ€æ ‡å¿—ï¼Œç”¨äºå‰ç«¯æ§åˆ¶
        self.cache_optimization_enabled = False  # ç¼“å­˜ä¼˜åŒ–å¼€å…³
        
        # ç›‘å¬çš„Redis Stream
        self.streams_to_monitor = {
            "fault_diagnosis_results": "fault_results_group",
            "vehicle_health_assessments": "health_group"
        }
        
        # ğŸš€ ç¼“å­˜ä¼˜åŒ–å™¨å®ä¾‹
        self.cache_optimizer = None
        
        # ğŸ”§ å¥åº·æ£€æŸ¥å‚æ•°
        self.last_activity_time = None
        self.health_check_interval = 300  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        self.max_idle_time = 600  # 10åˆ†é’Ÿé—²ç½®è¶…æ—¶
        self.processed_messages_count = 0
        
    async def initialize(self, websocket_manager):
        """åˆå§‹åŒ–æ¡¥æ¥ç»„ä»¶"""
        try:
            # è¿æ¥Redisï¼ˆä½¿ç”¨ä¸ç°æœ‰ç³»ç»Ÿç›¸åŒçš„é…ç½®ï¼‰
            self.redis_client = redis.from_url(
                self.redis_url,
                decode_responses=True,
                retry_on_timeout=True,
                health_check_interval=30
            )
            await self.redis_client.ping()
            
            # ä¿å­˜WebSocketç®¡ç†å™¨å¼•ç”¨
            self.websocket_manager = websocket_manager
            
            # åˆ›å»ºæ¶ˆè´¹è€…ç»„
            await self._create_consumer_groups()
            
            # ğŸš€ åˆå§‹åŒ–ç¼“å­˜ä¼˜åŒ–å™¨
            await self._initialize_cache_optimizer()
            
            logger.info("âœ… Redis Streamåˆ°å‰ç«¯æ¡¥æ¥ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¡¥æ¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def add_streams_to_monitor(self, streams_dict: Dict[str, str]):
        """åŠ¨æ€æ·»åŠ éœ€è¦ç›‘å¬çš„Redis StreamåŠå…¶æ¶ˆè´¹è€…ç»„ã€‚
        å‚æ•°ç¤ºä¾‹: {"fault_diagnosis_results": "cluster_results_group"}
        """
        if not self.redis_client:
            logger.error("âŒ æ¡¥æ¥å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ Stream")
            return False
        try:
            redis_conn = cast(redis.Redis, self.redis_client)
            # åˆå¹¶æ–°çš„Streamåˆ°ç›‘å¬åˆ—è¡¨
            self.streams_to_monitor.update(streams_dict)
            
            # ä¸ºæ–°å¢çš„Streamåˆ›å»ºæ¶ˆè´¹è€…ç»„
            for stream_name, group_name in streams_dict.items():
                try:
                    await redis_conn.xgroup_create(
                        stream_name,
                        group_name,
                        id="0",
                        mkstream=True
                    )
                    logger.info(f"âœ… æ·»åŠ ç›‘å¬Stream: {stream_name} -> {group_name}")
                except Exception as e:
                    if "BUSYGROUP" not in str(e):
                        logger.warning(f"åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥ {stream_name}: {e}")
            
            # å¦‚å½“å‰å·²åœ¨ç›‘æ§ï¼Œåˆ™é‡å¯æ ‡å‡†ç›‘æ§ä»¥çº³å…¥æ–°æµ
            if self.is_monitoring:
                self.is_running = False
                await asyncio.sleep(0.5)
                self.is_running = True
                asyncio.create_task(self._start_standard_monitoring())
                logger.info("ğŸ”„ å·²é‡å¯æ¡¥æ¥å™¨ç›‘å¬ä»¥åŒ…å«æ–°å¢Stream")
            return True
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ç›‘å¬Streamå¤±è´¥: {e}")
            return False
    
    async def _initialize_cache_optimizer(self):
        """åˆå§‹åŒ–ç¼“å­˜ä¼˜åŒ–å™¨"""
        # é¿å…é‡å¤åˆå§‹åŒ–
        if self.cache_optimizer is not None:
            logger.debug("ç¼“å­˜ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return
            
        try:
            from .stream_cache_optimizer import stream_cache_optimizer
            self.cache_optimizer = stream_cache_optimizer
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–è¿‡
            if hasattr(self.cache_optimizer, '_initialized') and self.cache_optimizer._initialized:
                logger.debug("ç¼“å­˜ä¼˜åŒ–å™¨å·²åœ¨å…¶ä»–åœ°æ–¹åˆå§‹åŒ–")
                return
                
            # åˆå§‹åŒ–ä¼˜åŒ–å™¨ä½†ä¸å¯åŠ¨
            success = await self.cache_optimizer.initialize(self.websocket_manager)
            if success:
                self.cache_optimizer._initialized = True
                logger.info("ğŸš€ ç¼“å­˜ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œå¯é€šè¿‡APIå¯ç”¨")
            else:
                logger.error("âŒ ç¼“å­˜ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
                self.cache_optimizer = None
                
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.cache_optimizer = None
        
    async def _create_consumer_groups(self):
        """åˆ›å»ºæ¶ˆè´¹è€…ç»„"""
        if not self.redis_client:
            logger.error("âŒ æ¡¥æ¥å™¨æœªåˆå§‹åŒ–(redis_clientä¸ºç©º)ï¼Œæ— æ³•åˆ›å»ºæ¶ˆè´¹è€…ç»„")
            return
        redis_conn = cast(redis.Redis, self.redis_client)
        for stream_name, group_name in self.streams_to_monitor.items():
            try:
                await redis_conn.xgroup_create(
                    stream_name, 
                    group_name, 
                    id="0", 
                    mkstream=True
                )
                logger.debug(f"åˆ›å»ºæ¶ˆè´¹è€…ç»„: {stream_name} -> {group_name}")
            except Exception as e:
                if "BUSYGROUP" not in str(e):
                    logger.warning(f"åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥ {stream_name}: {e}")

    async def start_monitoring(self):
        """å¼€å§‹ç›‘å¬Redis Streamå¹¶è½¬å‘æ•°æ®"""
        if not self.redis_client or not self.websocket_manager:
            logger.error("âŒ æ¡¥æ¥ç»„ä»¶æœªåˆå§‹åŒ–")
            return
        
        # é˜²æ­¢é‡å¤å¯åŠ¨ç›‘æ§
        if self.is_monitoring:
            logger.info("ğŸ“Š Redis Streamæ¡¥æ¥ç›‘æ§å·²åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
            return
            
        self.is_running = True
        self.is_monitoring = True # å¼€å§‹ç›‘æ§æ—¶è®¾ç½®æ ‡å¿—
        
        # ğŸš€ æ ¹æ®ç¼“å­˜ä¼˜åŒ–è®¾ç½®é€‰æ‹©ç›‘æ§æ¨¡å¼
        if self.cache_optimization_enabled and self.cache_optimizer:
            logger.info("ğŸš€ å¯åŠ¨Redis Streamç¼“å­˜ä¼˜åŒ–ç›‘æ§...")
            await self.cache_optimizer.start_optimized_monitoring()
        else:
            logger.info("ğŸš€ å¯åŠ¨Redis Streamæ ‡å‡†ç›‘æ§...")
            await self._start_standard_monitoring()

    async def _start_standard_monitoring(self):
        """å¯åŠ¨æ ‡å‡†ç›‘æ§æ¨¡å¼"""
        # åˆå§‹åŒ–æ´»åŠ¨æ—¶é—´
        self.last_activity_time = asyncio.get_event_loop().time()
        
        # å¯åŠ¨å¤šä¸ªç›‘å¬ä»»åŠ¡
        tasks = []
        
        # ç›‘å¬æ•…éšœè¯Šæ–­ç»“æœ
        tasks.append(
            asyncio.create_task(
                self._monitor_fault_results()
            )
        )
        
        # ç›‘å¬è½¦è¾†å¥åº·è¯„ä¼°
        tasks.append(
            asyncio.create_task(
                self._monitor_health_assessments()
            )
        )
        
        # ğŸ”§ æ·»åŠ å¥åº·æ£€æŸ¥ä»»åŠ¡
        tasks.append(
            asyncio.create_task(
                self._health_monitor_loop()
            )
        )
        
        try:
            await asyncio.gather(*tasks)
        except Exception as e:
            logger.error(f"âŒ ç›‘å¬ä»»åŠ¡å¼‚å¸¸: {e}")
        finally:
            self.is_running = False
            self.is_monitoring = False # åœæ­¢ç›‘æ§æ—¶é‡ç½®æ ‡å¿—

    async def enable_cache_optimization(self):
        """å¯ç”¨ç¼“å­˜ä¼˜åŒ–æ¨¡å¼"""
        if not self.cache_optimizer:
            logger.error("âŒ ç¼“å­˜ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–")
            return False
            
        self.cache_optimization_enabled = True
        logger.info("âœ… ç¼“å­˜ä¼˜åŒ–æ¨¡å¼å·²å¯ç”¨")
        return True

    async def disable_cache_optimization(self):
        """ç¦ç”¨ç¼“å­˜ä¼˜åŒ–æ¨¡å¼"""
        self.cache_optimization_enabled = False
        if self.cache_optimizer and self.cache_optimizer.is_running:
            await self.cache_optimizer.stop_monitoring()
        logger.info("ğŸ”„ ç¼“å­˜ä¼˜åŒ–æ¨¡å¼å·²ç¦ç”¨ï¼Œåˆ‡æ¢åˆ°æ ‡å‡†æ¨¡å¼")
        return True

    async def get_optimization_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        if self.cache_optimizer:
            return self.cache_optimizer.get_optimizer_stats()
        else:
            return {"error": "ç¼“å­˜ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–"}

    async def _monitor_fault_results(self):
        """ç›‘å¬æ•…éšœè¯Šæ–­ç»“æœæµ"""
        consumer_id = "frontend_bridge_fault"
        group_name = self.streams_to_monitor["fault_diagnosis_results"]
        
        if not self.redis_client:
            logger.error("âŒ æ¡¥æ¥å™¨æœªåˆå§‹åŒ–(redis_clientä¸ºç©º)ï¼Œæ— æ³•ç›‘å¬æ•…éšœè¯Šæ–­ç»“æœ")
            return
        redis_conn = cast(redis.Redis, self.redis_client)

        while self.is_running:
            try:
                # è¯»å–æ•…éšœè¯Šæ–­ç»“æœ
                messages = await redis_conn.xreadgroup(
                    group_name,
                    consumer_id,
                    {"fault_diagnosis_results": ">"},
                    count=10,
                    block=1000
                )
                
                for stream, msgs in messages:
                    for message_id, fields in msgs:
                        await self._forward_fault_result(fields, message_id)
                        
                        # ç¡®è®¤æ¶ˆæ¯å¤„ç†å®Œæˆ
                        await redis_conn.xack(
                            "fault_diagnosis_results",
                            group_name,
                            message_id
                        )
                        
                        # ğŸ”§ æ›´æ–°æ´»åŠ¨æ—¶é—´å’Œè®¡æ•°
                        self.last_activity_time = asyncio.get_event_loop().time()
                        self.processed_messages_count += 1
                        
            except Exception as e:
                logger.error(f"âŒ ç›‘å¬æ•…éšœç»“æœå¤±è´¥: {e}")
                await asyncio.sleep(1)

    async def _monitor_health_assessments(self):
        """ç›‘å¬è½¦è¾†å¥åº·è¯„ä¼°æµ"""
        consumer_id = "frontend_bridge_health"
        group_name = self.streams_to_monitor["vehicle_health_assessments"]
        
        if not self.redis_client:
            logger.error("âŒ æ¡¥æ¥å™¨æœªåˆå§‹åŒ–(redis_clientä¸ºç©º)ï¼Œæ— æ³•ç›‘å¬å¥åº·è¯„ä¼°ç»“æœ")
            return
        redis_conn = cast(redis.Redis, self.redis_client)

        while self.is_running:
            try:
                # è¯»å–å¥åº·è¯„ä¼°ç»“æœ
                messages = await redis_conn.xreadgroup(
                    group_name,
                    consumer_id,
                    {"vehicle_health_assessments": ">"},
                    count=5,
                    block=1000
                )
                
                for stream, msgs in messages:
                    for message_id, fields in msgs:
                        await self._forward_health_assessment(fields, message_id)
                        
                        # ç¡®è®¤æ¶ˆæ¯å¤„ç†å®Œæˆ
                        await redis_conn.xack(
                            "vehicle_health_assessments",
                            group_name,
                            message_id
                        )
                        
                        # ğŸ”§ æ›´æ–°æ´»åŠ¨æ—¶é—´å’Œè®¡æ•°
                        self.last_activity_time = asyncio.get_event_loop().time()
                        self.processed_messages_count += 1
                        
            except Exception as e:
                logger.error(f"âŒ ç›‘å¬å¥åº·è¯„ä¼°å¤±è´¥: {e}")
                await asyncio.sleep(1)

    async def _forward_fault_result(self, fields: Dict, message_id: str):
        """è½¬å‘æ•…éšœè¯Šæ–­ç»“æœåˆ°å‰ç«¯ï¼ˆè½»é‡çº§ï¼Œæ— é¢å¤–è®¡ç®—ï¼‰"""
        try:
            vehicle_id = fields.get("vehicle_id", "unknown")
            fault_type = fields.get("fault_type", "unknown")
            timestamp = fields.get("timestamp", datetime.now().isoformat())
            status = fields.get("status", "unknown")
            score = float(fields.get("score", "0.0"))
            
            # è§£æç‰¹å¾æ•°æ®
            features = {}
            try:
                features = json.loads(fields.get("features", "{}"))
            except json.JSONDecodeError:
                features = {}
            
            # è§£æä¼ æ„Ÿå™¨æ•°æ® - æ£€æŸ¥time_serieså’Œfrequency_spectrum
            sensor_data = {}
            try:
                sensor_data_raw = fields.get("sensor_data", "{}")
                sensor_data = json.loads(sensor_data_raw)
                # ğŸ” åªåœ¨å‡ºç°é—®é¢˜æ—¶è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼Œå‡å°‘æ—¥å¿—æ±¡æŸ“
                if "time_series" not in sensor_data or not sensor_data["time_series"]:
                    logger.debug(f"âš ï¸  [æ¡¥æ¥] {vehicle_id}-{fault_type} ç¼ºå°‘æˆ–ä¸ºç©ºçš„time_serieså­—æ®µ")
                # æ­£å¸¸æƒ…å†µä¸‹ä¸è¾“å‡ºè°ƒè¯•æ—¥å¿—ï¼Œæå‡æ€§èƒ½
            except json.JSONDecodeError as e:
                logger.warning(f"âŒ [æ¡¥æ¥] sensor_dataè§£æå¤±è´¥: {e}")
                sensor_data = {}
            
            # è§£æå›¾è¡¨æ•°æ®
            charts = {}
            try:
                charts = json.loads(fields.get("charts", "{}"))
            except json.JSONDecodeError:
                charts = {}
            
            # æ„å»ºæ ‡å‡†åŒ–å‰ç«¯æ¶ˆæ¯ï¼Œç¬¦åˆæ•°æ®æµé€»è¾‘
            frontend_message = {
                "fault_type": fault_type,
                "vehicle_id": vehicle_id,
                "timestamp": timestamp,
                "status": status,
                "score": score,  # æ•°å€¼ç±»å‹
                "features": features,
            }
            
            # ä¼˜å…ˆä»sensor_dataä¸­æå–æ—¶é—´åºåˆ—æ•°æ®ï¼ˆåç«¯å¢å¼ºæ¶æ„ï¼‰
            if "time_series" in sensor_data:
                frontend_message["time_series"] = sensor_data["time_series"]
            elif "time_series" in charts:
                frontend_message["time_series"] = charts["time_series"]
            
            # ä¼˜å…ˆä»sensor_dataä¸­æå–é¢‘è°±æ•°æ®ï¼ˆåç«¯å¢å¼ºæ¶æ„ï¼‰
            if "frequency_spectrum" in sensor_data:
                frontend_message["spectrum"] = sensor_data["frequency_spectrum"]
            elif "frequency_spectrum" in charts:
                frontend_message["spectrum"] = charts["frequency_spectrum"]
            elif "spectrum" in charts:
                frontend_message["spectrum"] = charts["spectrum"]
            
            # æ·»åŠ å›¾è¡¨é…ç½®
            chart_config = {}
            if "time_domain" in charts:
                chart_config["time_domain"] = charts["time_domain"]
            if "frequency_domain" in charts:
                chart_config["frequency_domain"] = charts["frequency_domain"]
            if chart_config:
                frontend_message["charts"] = chart_config
            
            # æ·»åŠ ä½ç½®ä¿¡æ¯
            frontend_message["location"] = self._get_location_from_vehicle_id(vehicle_id)
            
            # è®¡ç®—å¥åº·è¯„åˆ†
            if score <= 0.2:
                health_score = 95.0 - (score * 25)  # æ­£å¸¸èŒƒå›´ 95-90
            elif score <= 0.5:
                health_score = 90.0 - ((score - 0.2) * 100)  # è­¦å‘ŠèŒƒå›´ 90-60
            else:
                health_score = 60.0 - ((score - 0.5) * 120)  # æ•…éšœèŒƒå›´ 60-0
            
            frontend_message["health_score"] = max(0.0, min(100.0, health_score))
            
            # è½¬å‘åˆ°WebSocketå‰ç«¯ï¼ˆè½»é‡çº§æ“ä½œï¼‰
            if self.websocket_manager:
                await self.websocket_manager.broadcast_to_frontends(frontend_message)
                # ç§»é™¤é«˜é¢‘æ—¥å¿—è¾“å‡ºï¼Œæå‡æ€§èƒ½
            
        except Exception as e:
            logger.error(f"âŒ è½¬å‘æ•…éšœç»“æœå¤±è´¥: {e}")

    async def _forward_health_assessment(self, fields: Dict, message_id: str):
        """è½¬å‘å¥åº·è¯„ä¼°ç»“æœåˆ°å‰ç«¯ï¼ˆè½»é‡çº§ï¼Œæ— è®¡ç®—ï¼‰"""
        try:
            vehicle_id = fields.get("vehicle_id", "unknown")
            timestamp = fields.get("timestamp", datetime.now().isoformat())
            
            # è§£ææ•´ä½“å¥åº·æ•°æ®
            overall_health = {}
            try:
                overall_health = json.loads(fields.get("overall_health", "{}"))
            except json.JSONDecodeError:
                overall_health = {}
            
            # è§£ææ•…éšœçŠ¶æ€
            fault_states = {}
            try:
                fault_states = json.loads(fields.get("fault_states", "{}"))
            except json.JSONDecodeError:
                fault_states = {}
            
            # æ„å»ºå¥åº·è¯„ä¼°æ¶ˆæ¯
            health_message = {
                "message_type": "health_assessment",
                "vehicle_id": vehicle_id,  # å…³é”®å­—æ®µï¼šè½¦è¾†ID
                "timestamp": timestamp,
                "health_score": overall_health.get("health_score", 0.0),  # å…³é”®å­—æ®µï¼šå¥åº·è¯„åˆ†
                "overall_status": overall_health.get("overall_status", "unknown"),
                "active_faults": overall_health.get("active_faults", []),
                "fault_details": fault_states,
                "location": self._get_location_from_vehicle_id(vehicle_id),
                "data_source": "redis_stream",
                "message_id": message_id
            }
            
            # è½¬å‘åˆ°WebSocketå‰ç«¯
            if self.websocket_manager:
                await self.websocket_manager.broadcast_to_frontends(health_message)
                # ç§»é™¤é«˜é¢‘æ—¥å¿—è¾“å‡ºï¼Œæå‡æ€§èƒ½
            
        except Exception as e:
            logger.error(f"âŒ è½¬å‘å¥åº·è¯„ä¼°å¤±è´¥: {e}")

    def _get_location_from_vehicle_id(self, vehicle_id: str) -> str:
        """ä»è½¦è¾†IDæ¨å¯¼ä½ç½®ä¿¡æ¯ï¼ˆè½»é‡çº§æ“ä½œï¼Œæ— å¤æ‚è®¡ç®—ï¼‰"""
        if not vehicle_id or vehicle_id == "unknown":
            return "æœªçŸ¥ä½ç½®"
        
        # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼Œæ— å¤æ‚è®¡ç®—
        if "ç²¤B" in vehicle_id or "SEAL" in vehicle_id:
            return "æ·±åœ³ç¦ç”°åŒº"
        elif "é™•A" in vehicle_id:
            if "QIN" in vehicle_id:
                return "è¥¿å®‰é«˜æ–°åŒº"
            elif "HAN" in vehicle_id:
                return "è¥¿å®‰é«˜æ–°åŒº"
            else:
                return "è¥¿å®‰å¸‚"
        else:
            return "æœªçŸ¥ä½ç½®"

    async def stop_monitoring(self):
        """åœæ­¢ç›‘å¬"""
        self.is_running = False
        self.is_monitoring = False # åœæ­¢ç›‘æ§æ—¶é‡ç½®æ ‡å¿—
        if self.redis_client:
            await self.redis_client.close()
        logger.info("ğŸ›‘ Redis Streamæ¡¥æ¥ç»„ä»¶å·²åœæ­¢")

    def get_bridge_stats(self) -> Dict[str, Any]:
        """è·å–æ¡¥æ¥ç»„ä»¶ç»Ÿè®¡ä¿¡æ¯ï¼ˆè½»é‡çº§ï¼‰"""
        current_time = asyncio.get_event_loop().time() if asyncio.get_event_loop().is_running() else 0
        idle_time = (current_time - self.last_activity_time) if self.last_activity_time else 0
        
        return {
            "is_running": self.is_running,
            "is_monitoring": self.is_monitoring, # æ·»åŠ ç›‘æ§çŠ¶æ€
            "redis_connected": self.redis_client is not None,
            "websocket_connected": self.websocket_manager is not None,
            "monitored_streams": list(self.streams_to_monitor.keys()),
            "processed_messages": self.processed_messages_count,
            "idle_time_seconds": idle_time,
            "health_status": "healthy" if idle_time < self.max_idle_time else "unhealthy"
        }

    async def _health_monitor_loop(self):
        """å¥åº·ç›‘æ§å¾ªç¯ï¼Œå®šæœŸæ£€æŸ¥æ¡¥æ¥å™¨çŠ¶æ€"""
        while self.is_running:
            try:
                await asyncio.sleep(self.health_check_interval)
                
                if not self.is_running:
                    break
                    
                current_time = asyncio.get_event_loop().time()
                idle_time = current_time - (self.last_activity_time or current_time)
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶é—²ç½®
                if idle_time > self.max_idle_time:
                    logger.warning(f"âš ï¸ æ¡¥æ¥å™¨é—²ç½®è¶…æ—¶: {idle_time:.1f}ç§’ > {self.max_idle_time}ç§’")
                    logger.info("ğŸ”„ å°è¯•é‡æ–°å¯åŠ¨æ¡¥æ¥å™¨ç›‘å¬...")
                    
                    # é‡ç½®çŠ¶æ€å¹¶é‡å¯
                    await self._restart_monitoring()
                else:
                    logger.debug(f"ğŸŸ¢ æ¡¥æ¥å™¨å¥åº·æ£€æŸ¥é€šè¿‡: é—²ç½®{idle_time:.1f}ç§’, å·²å¤„ç†{self.processed_messages_count}æ¡æ¶ˆæ¯")
                    
            except Exception as e:
                logger.error(f"âŒ å¥åº·ç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(30)  # å¼‚å¸¸æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´

    async def _restart_monitoring(self):
        """é‡æ–°å¯åŠ¨ç›‘å¬ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        try:
            # é‡ç½®æ´»åŠ¨æ—¶é—´
            self.last_activity_time = asyncio.get_event_loop().time()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§¯å‹æ¶ˆæ¯éœ€è¦å¤„ç†
            pending_count = await self._check_pending_messages()
            
            if pending_count > 0:
                logger.info(f"ğŸ“¦ å‘ç°{pending_count}æ¡ç§¯å‹æ¶ˆæ¯ï¼Œå°†ç»§ç»­å¤„ç†")
            else:
                logger.info("âœ… æ— ç§¯å‹æ¶ˆæ¯ï¼Œæ¡¥æ¥å™¨çŠ¶æ€æ­£å¸¸")
                
        except Exception as e:
            logger.error(f"âŒ é‡å¯ç›‘å¬å¤±è´¥: {e}")

    async def _check_pending_messages(self) -> int:
        """æ£€æŸ¥ç§¯å‹æ¶ˆæ¯æ•°é‡"""
        total_pending = 0
        try:
            if not self.redis_client:
                logger.error("âŒ æ¡¥æ¥å™¨æœªåˆå§‹åŒ–(redis_clientä¸ºç©º)ï¼Œæ— æ³•æ£€æŸ¥ç§¯å‹æ¶ˆæ¯")
                return 0
            redis_conn = cast(redis.Redis, self.redis_client)
            for stream_name, group_name in self.streams_to_monitor.items():
                try:
                    # è·å–æ¶ˆè´¹è€…ç»„ä¿¡æ¯
                    consumers = await redis_conn.xinfo_consumers(stream_name, group_name)
                    for consumer in consumers:
                        if consumer['name'] in ['frontend_bridge_fault', 'frontend_bridge_health']:
                            pending = consumer['pending']
                            total_pending += pending
                            if pending > 0:
                                logger.info(f"ğŸ“¦ {consumer['name']}: {pending}æ¡ç§¯å‹æ¶ˆæ¯")
                except Exception as e:
                    logger.debug(f"æ£€æŸ¥{stream_name}ç§¯å‹æ¶ˆæ¯å¤±è´¥: {e}")
                    
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç§¯å‹æ¶ˆæ¯å¤±è´¥: {e}")
            
        return total_pending

# å…¨å±€æ¡¥æ¥ç»„ä»¶å®ä¾‹
stream_bridge = StreamToFrontendBridge() 