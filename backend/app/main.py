# pyright: reportMissingImports=false

import os
import sys
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ï¼Œç¡®ä¿åœ¨ä»»ä½•å…¶ä»–å¯¼å…¥ä¹‹å‰æ‰§è¡Œ
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from contextlib import asynccontextmanager
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import aiohttp
import asyncio

from .core.config import API_CONFIG
from .websockets.realtime_diagnosis import manager as realtime_diagnosis_manager, handle_frontend_connection, handle_datasource_connection
from .websockets.realtime_diagnosis import handle_fault_data_from_redis, handle_analysis_result_from_redis
from .routers import auth, diagnosis, samples, users, ai_chat, queue_status
from .core.database import Base, engine
from . import models

# å¯¼å…¥ç®€å•å†…å­˜é˜Ÿåˆ—æœåŠ¡ï¼ˆå®Œå…¨ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼‰
from .services.simple_queue import simple_queue, TOPICS

# å¯¼å…¥Redisé˜Ÿåˆ—æœåŠ¡
from .services.redis_queue.redis_queue import redis_queue

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def check_and_setup_api_key():
    """æ£€æŸ¥å¹¶è®¾ç½®API Key - è‡ªåŠ¨ä½¿ç”¨é»˜è®¤Key"""
    # é»˜è®¤çš„API Key
    default_api_key = "sk-0de3188307e44558a60d09799df2702c"
    
    api_key = os.getenv('QWEN_API_KEY')
    
    if not api_key:
        logger.info("ğŸ”§ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤API Key")
        # è‡ªåŠ¨è®¾ç½®é»˜è®¤API Key
        os.environ['QWEN_API_KEY'] = default_api_key
        api_key = default_api_key
        logger.info(f"âœ… å·²è‡ªåŠ¨è®¾ç½®API Key: {api_key[:10]}...{api_key[-5:]}")
    
    else:
        # éªŒè¯ç°æœ‰çš„API Keyæ ¼å¼
        if not api_key.startswith('sk-'):
            logger.warning(f"âš ï¸  API Key æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤Key")
            os.environ['QWEN_API_KEY'] = default_api_key
            api_key = default_api_key
    
    # å¿«é€ŸéªŒè¯ï¼ˆå¯é€‰ï¼Œç½‘ç»œé—®é¢˜æ—¶è·³è¿‡ï¼‰
    try:
        is_valid = await verify_api_key(api_key)
        if is_valid:
            logger.info(f"âœ… API Key éªŒè¯æˆåŠŸ: {api_key[:10]}...{api_key[-5:]}")
        else:
            logger.warning(f"âš ï¸  API Key éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­å¯åŠ¨")
    except Exception as e:
        logger.info(f"âš ï¸  API Key éªŒè¯è·³è¿‡ (ç½‘ç»œé—®é¢˜): {e}")
    
    return True  # æ€»æ˜¯è¿”å›Trueï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¯åŠ¨

async def verify_api_key(api_key: str) -> bool:
    """éªŒè¯API Keyæ˜¯å¦æœ‰æ•ˆ"""
    try:
        payload = {
            "model": "qwen-plus",
            "input": {
                "messages": [
                    {
                        "role": "user",
                        "content": "ä½ å¥½"
                    }
                ]
            },
            "parameters": {
                "result_format": "message",
                "temperature": 0.1,
                "max_tokens": 10
            }
        }
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
                json=payload,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                if response.status == 200:
                    return True
                else:
                    logger.error(f"API KeyéªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    return False
    
    except asyncio.TimeoutError:
        logger.warning("âš ï¸  API KeyéªŒè¯è¶…æ—¶ï¼Œè·³è¿‡éªŒè¯")
        return True  # ç½‘ç»œé—®é¢˜æ—¶å‡è®¾æœ‰æ•ˆ
    except Exception as e:
        logger.error(f"API KeyéªŒè¯å¼‚å¸¸: {e}")
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    # åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºæ•°æ®åº“è¡¨
    logger.info("åˆ›å»ºæ•°æ®åº“è¡¨...")
    try:
        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")
        
        # åˆå§‹åŒ–é»˜è®¤ç”¨æˆ·
        from .core.database import SessionLocal
        from .crud.user import get_user_by_username, create_user
        from .schemas.user import UserCreate
        
        db = SessionLocal()
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨adminç”¨æˆ·
            admin_user = get_user_by_username(db, "admin")
            if not admin_user:
                # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
                admin_user_data = UserCreate(
                    username="admin",
                    password="admin123",
                    name="ç®¡ç†å‘˜",
                    email="admin@vtox.com",
                    role="admin"
                )
                create_user(db, admin_user_data)
                logger.info("âœ… åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·: admin/admin123")
            else:
                logger.info("âœ… ç®¡ç†å‘˜ç”¨æˆ·å·²å­˜åœ¨")
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        logger.warning("ç³»ç»Ÿå°†ç»§ç»­å¯åŠ¨ï¼Œä½†å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    
    # æ£€æŸ¥å’Œè®¾ç½®API Key
    logger.info("æ£€æŸ¥APIé…ç½®...")
    await check_and_setup_api_key()
    
    # åˆå§‹åŒ–Redisé˜Ÿåˆ—
    logger.info("åˆå§‹åŒ–Redisé˜Ÿåˆ—...")
    redis_connected = await redis_queue.connect()
    
    # âš ï¸  å·²ç¦ç”¨æ—§çš„é˜Ÿåˆ—ç³»ç»Ÿï¼Œç°åœ¨ä½¿ç”¨Redis Streamç³»ç»Ÿ + æ¡¥æ¥ç»„ä»¶
    logger.info("ğŸ”§ è·³è¿‡æ—§é˜Ÿåˆ—ç³»ç»Ÿå¯åŠ¨ï¼ˆå·²ä½¿ç”¨Redis Stream + æ¡¥æ¥ç»„ä»¶æ›¿ä»£ï¼‰")
    
    # ğŸ”§ è‡ªåŠ¨å¯åŠ¨StreamToFrontendBridge - ä¿®å¤æ¶ˆæ¯é¢‘ç‡ä½çš„é—®é¢˜
    logger.info("ğŸŒ‰ åˆå§‹åŒ–Redis Streamåˆ°å‰ç«¯æ¡¥æ¥å™¨...")
    try:
        # å¯¼å…¥å¹¶åˆå§‹åŒ–æ¡¥æ¥å™¨
        from .services.redis_stream.stream_to_frontend_bridge import stream_bridge
        
        # ä½¿ç”¨realtime_diagnosis_managerä½œä¸ºWebSocketç®¡ç†å™¨
        success = await stream_bridge.initialize(realtime_diagnosis_manager)
        
        if success:
            logger.info("âœ… Redis Streamæ¡¥æ¥å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # ğŸš€ å…³é”®ä¿®å¤ï¼šå¯åŠ¨ç›‘å¬å¾ªç¯
            if not stream_bridge.is_monitoring:
                asyncio.create_task(stream_bridge.start_monitoring())
                logger.info("ğŸš€ Redis Streamæ¡¥æ¥å™¨ç›‘å¬å¾ªç¯å·²å¯åŠ¨")
            else:
                logger.info("ğŸ“Š Redis Streamæ¡¥æ¥å™¨ç›‘å¬å·²åœ¨è¿è¡Œ")
        else:
            logger.error("âŒ Redis Streamæ¡¥æ¥å™¨å¯åŠ¨å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨Redis Streamæ¡¥æ¥å™¨å¼‚å¸¸: {e}")
        logger.warning("å‰ç«¯å¯èƒ½æ— æ³•æ¥æ”¶å®æ—¶è¯Šæ–­ç»“æœ")
    
    # ğŸš€ å¯åŠ¨è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡
    logger.info("ğŸ”„ å¯åŠ¨è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡...")
    try:
        from .services.auto_refresh_service import start_auto_refresh_service
        await start_auto_refresh_service()
        logger.info("âœ… è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡å¯åŠ¨æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡å¤±è´¥: {e}")
        logger.warning("ç³»ç»Ÿå°†ç»§ç»­è¿è¡Œï¼Œä½†å¯èƒ½å‡ºç°æ•°æ®è¿‡æœŸé—®é¢˜")
    
    # ğŸš€ å¯åŠ¨åˆ†å¸ƒå¼é›†ç¾¤ï¼ˆåå°ä»»åŠ¡ï¼Œé»˜è®¤ç¦ç”¨ï¼‰
    logger.info("ğŸ—ï¸ å‡†å¤‡åˆå§‹åŒ–VTOXåˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤ï¼ˆåå°ä»»åŠ¡ï¼‰...")
    cluster_manager = None
    try:
        # å¯¼å…¥é›†ç¾¤ç®¡ç†å™¨
        import sys
        from pathlib import Path
        
        # æ·»åŠ clusterç›®å½•åˆ°Pythonè·¯å¾„
        cluster_path = Path(__file__).parent.parent.parent / "cluster"
        if str(cluster_path) not in sys.path:
            sys.path.insert(0, str(cluster_path))
        
        # å¯¼å…¥ClusterManager
        from start_cluster import ClusterManager
        
        # ä»ç¯å¢ƒå˜é‡è·å–é›†ç¾¤æ¨¡å¼ - é»˜è®¤ç¦ç”¨é›†ç¾¤
        cluster_mode = os.getenv('VTOX_CLUSTER_MODE', 'development')
        cluster_workers = int(os.getenv('VTOX_CLUSTER_WORKERS', '1'))  # ğŸ”§ è½»é‡é…ç½®ï¼šå‡å°‘åˆ°1ä¸ªWorker
        # é»˜è®¤ç¦ç”¨ï¼Œæ‰‹åŠ¨å¼€å¯
        cluster_enabled = os.getenv('VTOX_CLUSTER_ENABLED', 'false').lower() == 'true'
        
        if not cluster_enabled:
            logger.info("ğŸ“Š åˆ†å¸ƒå¼é›†ç¾¤å·²ç¦ç”¨ï¼ˆé€šè¿‡VTOX_CLUSTER_ENABLED=falseè®¾ç½®ï¼‰")
            logger.warning("âš ï¸ ç³»ç»Ÿå°†ä»¥å•æœºæ¨¡å¼è¿è¡Œï¼ŒåŠŸèƒ½å—é™")
            app.state.cluster_manager = None
        else:
            async def start_cluster_bg():
                nonlocal cluster_manager
                try:
                    cluster_manager = ClusterManager(mode=cluster_mode)
                    cluster_manager.redis_url = "redis://localhost:6379"
                    logger.info(f"ğŸ“Š é›†ç¾¤é…ç½®: æ¨¡å¼={cluster_mode}, Workeræ•°é‡={cluster_workers}")
                    logger.info("ğŸ”„ åå°å¯åŠ¨é›†ç¾¤æœåŠ¡...")
                    if await cluster_manager.initialize_cluster():
                        if await cluster_manager.start_cluster(custom_workers=cluster_workers):
                            app.state.cluster_manager = cluster_manager
                            logger.info("âœ… é›†ç¾¤å·²åœ¨åå°å¯åŠ¨")
                            try:
                                from .services.redis_stream.stream_to_frontend_bridge import stream_bridge
                                await stream_bridge.add_streams_to_monitor({
                                    "fault_diagnosis_results": "cluster_results_group",
                                    "vehicle_health_assessments": "cluster_health_group"
                                })
                                if not stream_bridge.is_monitoring:
                                    asyncio.create_task(stream_bridge.start_monitoring())
                            except Exception as e:
                                logger.warning(f"âš ï¸ é…ç½®æ¡¥æ¥å™¨ç›‘å¬å¤±è´¥: {e}")
                            try:
                                from app.services.cluster.service_registry import register_gateway_service, get_service_registry
                                import redis.asyncio as redis
                                redis_client = redis.from_url(cluster_manager.redis_url, decode_responses=True)
                                registry = await get_service_registry(redis_client)
                                gateway_client = await register_gateway_service(registry, host="localhost", port=8000)
                                asyncio.create_task(gateway_client.start())
                            except Exception as e:
                                logger.warning(f"âš ï¸ æ³¨å†ŒAPIç½‘å…³åˆ°æœåŠ¡æ³¨å†Œè¡¨å¤±è´¥: {e}")
                        else:
                            logger.error("âŒ é›†ç¾¤å¯åŠ¨å¤±è´¥ï¼ˆåå°ï¼‰")
                            app.state.cluster_manager = None
                    else:
                        logger.error("âŒ é›†ç¾¤åˆå§‹åŒ–å¤±è´¥ï¼ˆåå°ï¼‰")
                        app.state.cluster_manager = None
                except Exception as e:
                    logger.error(f"âŒ åå°é›†ç¾¤å¼‚å¸¸: {e}")
                    app.state.cluster_manager = None

            asyncio.create_task(start_cluster_bg())
            logger.info("ğŸš€ é›†ç¾¤åå°å¯åŠ¨ä»»åŠ¡å·²åˆ›å»ºï¼Œä¸é˜»å¡API")
            
    except Exception as e:
        logger.error(f"âŒ é›†ç¾¤å‡†å¤‡é˜¶æ®µå¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼Œä¸é˜»å¡APIï¼‰: {e}")
        app.state.cluster_manager = None
    
    # æ³¨é‡Šæ‰çš„ä»£ç  - é¿å…ä¸Redis Streamç³»ç»Ÿé‡å¤å¤„ç†
    # å¯åŠ¨ç®€å•å†…å­˜é˜Ÿåˆ—æœåŠ¡ï¼ˆå®Œå…¨ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼‰
    # logger.info("å¯åŠ¨å†…å­˜é˜Ÿåˆ—æœåŠ¡...")
    # try:
    #     # è®¾ç½®é˜Ÿåˆ—æ¶ˆæ¯å¤„ç†å™¨
    #     simple_queue.subscribe(TOPICS['FAULT_DATA'], handle_fault_data_from_redis)
    #     simple_queue.subscribe(TOPICS['ANALYSIS_RESULTS'], handle_analysis_result_from_redis)
    #     
    #     # å¯åŠ¨é˜Ÿåˆ—æ¶ˆè´¹è€…
    #     asyncio.create_task(simple_queue.start_consuming())
    #     logger.info("âœ… å†…å­˜é˜Ÿåˆ—æœåŠ¡å¯åŠ¨å®Œæˆ")
    #     
    # except Exception as e:
    #     logger.error(f"å¯åŠ¨å†…å­˜é˜Ÿåˆ—æœåŠ¡å¤±è´¥: {e}", exc_info=True)
    #     logger.warning("ç³»ç»Ÿå°†ä»¥åŸºç¡€æ¨¡å¼è¿è¡Œ")
    # 
    # # å¦‚æœRedisè¿æ¥æˆåŠŸï¼Œå¯åŠ¨Redisé˜Ÿåˆ—æœåŠ¡
    # if redis_connected:
    #     try:
    #         logger.info("å¯åŠ¨Redisé˜Ÿåˆ—æœåŠ¡...")
    #         # è®¾ç½®Redisé˜Ÿåˆ—æ¶ˆæ¯å¤„ç†å™¨
    #         redis_queue.subscribe(TOPICS['FAULT_DATA'], handle_fault_data_from_redis)
    #         redis_queue.subscribe(TOPICS['ANALYSIS_RESULTS'], handle_analysis_result_from_redis)
    #         
    #         # å¯åŠ¨Redisé˜Ÿåˆ—æ¶ˆè´¹è€…
    #         asyncio.create_task(redis_queue.start_consuming())
    #         logger.info("âœ… Redisé˜Ÿåˆ—æœåŠ¡å¯åŠ¨å®Œæˆ")
    #     except Exception as e:
    #         logger.error(f"å¯åŠ¨Redisé˜Ÿåˆ—æœåŠ¡å¤±è´¥: {e}", exc_info=True)
    #         logger.warning("ç³»ç»Ÿå°†ç»§ç»­ä½¿ç”¨ç®€å•å†…å­˜é˜Ÿåˆ—")
    # else:
    #     logger.warning("Redisè¿æ¥å¤±è´¥ï¼Œç³»ç»Ÿå°†ç»§ç»­ä½¿ç”¨ç®€å•å†…å­˜é˜Ÿåˆ—")
    
    # ç°åœ¨æ•°æ®æµç¨‹ï¼šæ¨¡æ‹Ÿå™¨ â†’ FastAPI â†’ Redis Stream â†’ æ¡¥æ¥ç»„ä»¶ â†’ WebSocket â†’ å‰ç«¯
    logger.info("âœ… ç³»ç»Ÿå°†ä½¿ç”¨Redis Stream + æ¡¥æ¥ç»„ä»¶æ¶æ„")
    
    # å¯åŠ¨æ—¶æ‰§è¡Œçš„ä»£ç 
    logger.info("Application startup complete.")
    yield
    
    # å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
    logger.info("æ­£åœ¨å…³é—­åº”ç”¨...")
    
    # åœæ­¢åˆ†å¸ƒå¼é›†ç¾¤
    logger.info("åœæ­¢åˆ†å¸ƒå¼é›†ç¾¤...")
    try:
        cluster_manager = getattr(app.state, 'cluster_manager', None)
        if cluster_manager:
            await cluster_manager.stop_cluster()
            logger.info("âœ… åˆ†å¸ƒå¼é›†ç¾¤å·²åœæ­¢")
        else:
            logger.info("ğŸ“Š æœªå¯åŠ¨åˆ†å¸ƒå¼é›†ç¾¤ï¼Œæ— éœ€åœæ­¢")
    except Exception as e:
        logger.error(f"åœæ­¢åˆ†å¸ƒå¼é›†ç¾¤æ—¶å‡ºé”™: {e}")
    
    # åœæ­¢è‡ªåŠ¨åˆ·æ–°æœåŠ¡
    logger.info("åœæ­¢è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡...")
    try:
        from .services.auto_refresh_service import stop_auto_refresh_service
        await stop_auto_refresh_service()
        logger.info("è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡å·²åœæ­¢ã€‚")
    except Exception as e:
        logger.error(f"åœæ­¢è‡ªåŠ¨æ•°æ®åˆ·æ–°æœåŠ¡æ—¶å‡ºé”™: {e}")
    
    # åœæ­¢å†…å­˜é˜Ÿåˆ—æœåŠ¡
    logger.info("åœæ­¢å†…å­˜é˜Ÿåˆ—æœåŠ¡...")
    try:
        await simple_queue.stop()
        logger.info("å†…å­˜é˜Ÿåˆ—æœåŠ¡å·²åœæ­¢ã€‚")
    except Exception as e:
        logger.error(f"åœæ­¢å†…å­˜é˜Ÿåˆ—æœåŠ¡æ—¶å‡ºé”™: {e}")
    
    # åœæ­¢Redisé˜Ÿåˆ—æœåŠ¡
    logger.info("åœæ­¢Redisé˜Ÿåˆ—æœåŠ¡...")
    try:
        await redis_queue.stop()
        logger.info("Redisé˜Ÿåˆ—æœåŠ¡å·²åœæ­¢ã€‚")
    except Exception as e:
        logger.error(f"åœæ­¢Redisé˜Ÿåˆ—æœåŠ¡æ—¶å‡ºé”™: {e}")
    
    # æ¸…ç†WebSocketèµ„æº
    from .websockets.realtime_diagnosis import shutdown_event
    await shutdown_event()
    
    logger.info("Application shutdown complete.")

# è®¾ç½®JSONå“åº”ç¼–ç 
from fastapi.responses import JSONResponse
from fastapi.encoders import jsonable_encoder
import json

# ç¡®ä¿JSONå“åº”ä½¿ç”¨UTF-8ç¼–ç 
class UTF8JSONResponse(JSONResponse):
    def render(self, content) -> bytes:
        return json.dumps(
            jsonable_encoder(content),
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="åŒé—´çŸ­è·¯æ•…éšœè¯Šæ–­ç³»ç»ŸAPI",
    description="ç”µæœºåŒé—´çŸ­è·¯æ•…éšœè¯Šæ–­ç³»ç»Ÿåç«¯API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan,
    default_response_class=UTF8JSONResponse  # è®¾ç½®é»˜è®¤å“åº”ç±»
)

# é…ç½®CORSä¸­é—´ä»¶ï¼Œå…è®¸è·¨åŸŸè¯·æ±‚
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œå®æ—¶è¯Šæ–­WebSocketè·¯ç”±
app.websocket("/ws/frontend")(handle_frontend_connection)
app.websocket("/ws/datasource")(handle_datasource_connection)

# æ³¨å†Œæ‰€æœ‰è·¯ç”±
app.include_router(auth.router)
app.include_router(diagnosis.router)
app.include_router(samples.router)
app.include_router(users.router)
app.include_router(ai_chat.router)
app.include_router(queue_status.router)

# æ³¨å†Œåˆ†å¸ƒå¼è¯Šæ–­è·¯ç”±
from .routers import diagnosis_stream
app.include_router(diagnosis_stream.router)

# æ³¨å†Œè½¦é˜Ÿç®¡ç†è·¯ç”±
from .routers import vehicle_fleet
app.include_router(vehicle_fleet.router)

# æ³¨å†Œé›†ç¾¤çŠ¶æ€è·¯ç”±
from .routers import cluster_status
app.include_router(cluster_status.router, tags=["é›†ç¾¤çŠ¶æ€"])

# æ³¨å†Œååé‡é…ç½®ç®¡ç†è·¯ç”±
from .routers import throughput_config_api
app.include_router(throughput_config_api.router, tags=["ååé‡é…ç½®"])

# æ ¹è·¯ç”±
@app.get("/", summary="APIæ ¹ç›®å½•")
async def root():
    """
    APIæ ¹è·¯å¾„
    æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€å’Œé›†ç¾¤ä¿¡æ¯
    """
    # æ£€æŸ¥é›†ç¾¤çŠ¶æ€
    cluster_info = {
        "cluster_enabled": True,  # é»˜è®¤å¯ç”¨é›†ç¾¤
        "cluster_status": "unknown",
        "worker_count": 0,
        "deployment_mode": "cluster",  # é»˜è®¤é›†ç¾¤æ¨¡å¼
        "service_type": "distributed"  # æœåŠ¡ç±»å‹
    }
    
    try:
        cluster_manager = getattr(app.state, 'cluster_manager', None)
        if cluster_manager and cluster_manager.is_running:
            cluster_info.update({
                "cluster_enabled": True,
                "cluster_status": "running",
                "worker_count": len(cluster_manager.worker_nodes),
                "deployment_mode": cluster_manager.mode,
                "service_type": "distributed_cluster"
            })
        else:
            # å¦‚æœcluster_managerä¸å­˜åœ¨æˆ–æœªè¿è¡Œï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ç¦ç”¨çŠ¶æ€
            cluster_enabled = os.getenv('VTOX_CLUSTER_ENABLED', 'true').lower() == 'true'
            if not cluster_enabled:
                cluster_info.update({
                    "cluster_enabled": False,
                    "cluster_status": "disabled",
                    "worker_count": 0,
                    "deployment_mode": "standalone",
                    "service_type": "legacy_mode"
                })
            else:
                cluster_info.update({
                    "cluster_enabled": True,
                    "cluster_status": "failed",
                    "worker_count": 0,
                    "deployment_mode": "cluster",
                    "service_type": "cluster_failed"
                })
    except Exception:
        pass  # å¿½ç•¥é”™è¯¯ï¼Œä¿æŒé»˜è®¤å€¼
    
    return {
        "message": "åŒé—´çŸ­è·¯æ•…éšœè¯Šæ–­ç³»ç»ŸAPI",
        "status": "è¿è¡Œä¸­",
        "version": "1.0.0",
        "queue_type": "redis_stream",
        "cluster_info": cluster_info,
        "architecture": "åˆ†å¸ƒå¼å¾®æœåŠ¡é›†ç¾¤ (é»˜è®¤)",
        "description": "é›†ç¾¤æœåŠ¡å·²æ›¿ä»£å•æœºæœåŠ¡ï¼Œæä¾›é«˜æ€§èƒ½åˆ†å¸ƒå¼æ•…éšœè¯Šæ–­"
    }

 